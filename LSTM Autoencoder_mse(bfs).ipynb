{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob, os\n",
    "from keras import layers as ly\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Lambda\n",
    "from keras import losses\n",
    "from keras.models import model_from_json\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir = './sequence/*'\n",
    "dir = './latest_sequence/bfs-character/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file read\n",
    "all_names = []\n",
    "all_data = []\n",
    "sequence_length = []\n",
    "alpha = list(string.ascii_uppercase)\n",
    "data_length = len(glob.glob(dir))\n",
    "file_predix = './latest_sequence/bfs-character/graph'\n",
    "for index in range(data_length):\n",
    "    filename = file_predix + str(index) + \"-*\"\n",
    "    files = glob.glob(filename)\n",
    "    for file in files:\n",
    "        datasets = []\n",
    "        all_names.append(file.split('/')[-1].replace('.txt', ''))\n",
    "        for rf in open(file, 'r'):\n",
    "            (u, v, w) = rf[1:-2].split(', ')\n",
    "            datasets.append([alpha.index(u[1])+1, alpha.index(v[1]) +1, float(w)])\n",
    "        sequence_length.append(len(datasets))\n",
    "        all_data.append(datasets)\n",
    "all_data = np.array([np.array(arr) for arr in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, train_name, test_name = train_test_split(all_data, all_names, test_size=0.3)\n",
    "x_test, x_val, test_name, val_name = train_test_split(x_test, test_name, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name\n",
    "tr_names= []\n",
    "for name in train_name:\n",
    "    tr_names.append(name.split('-')[0].replace('graph', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max(sequence_length)\n",
    "n_features = 3\n",
    "batch_size = 32\n",
    "epochs = 500\n",
    "steps_per_epoch = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    loss1 = losses.mean_squared_error(y_true, y_pred)\n",
    "    #loss2 = losses.kld(y_true, y_pred)\n",
    "    return loss1# * 0.7 + loss2 * 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def repeat_vector(args):\n",
    "    layer_to_repeat = args[0]\n",
    "    sequence_layer = args[1]\n",
    "    return RepeatVector(K.shape(sequence_layer)[1])(layer_to_repeat)\n",
    "    \n",
    "\n",
    "inputs = Input(shape=(None, 3))\n",
    "encoded = LSTM(128, return_sequences=True)(inputs)  #activation 안적으면 tanh\n",
    "encoded = LSTM(64)(encoded)\n",
    "\n",
    "decoded = Lambda(repeat_vector, output_shape=(None, 64)) ([encoded, inputs]) # inputs의 shape[1] 만큼 encoded 를 반복 생성\n",
    "\n",
    "decoded = LSTM(64, return_sequences=True)(decoded)\n",
    "decoded = LSTM(128, return_sequences=True)(decoded)\n",
    "decoded = TimeDistributed(Dense(3))(decoded)\n",
    "encoder = Model(inputs, encoded)\n",
    "\n",
    "lstm_autoencoder = Model(inputs, decoded)\n",
    "lstm_autoencoder.compile(loss=custom_loss, optimizer=Adam())#lr=1e-2, decay=0.9))\n",
    "#lstm_autoencoder_500 = lstm_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_generator(x_val):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        yield np.array([x_val[idx]]), np.array([x_val[idx]])\n",
    "        idx += 1\n",
    "        if idx >= len(x_val):\n",
    "            idx = 0\n",
    "\n",
    "def train_generator(x_train):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        yield np.array([x_train[idx]]), np.array([x_train[idx]])\n",
    "        idx += 1\n",
    "        if idx >= len(x_train):\n",
    "            idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/300\n",
      "6468/6468 [==============================] - 61s 9ms/step - loss: 37.4117 - val_loss: 19.9987\n",
      "Epoch 2/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 19.3262 - val_loss: 15.7625\n",
      "Epoch 3/300\n",
      "6468/6468 [==============================] - 61s 10ms/step - loss: 16.1341 - val_loss: 14.2765\n",
      "Epoch 4/300\n",
      "6468/6468 [==============================] - 61s 9ms/step - loss: 13.6860 - val_loss: 11.6974\n",
      "Epoch 5/300\n",
      "6468/6468 [==============================] - 61s 9ms/step - loss: 11.2654 - val_loss: 9.9855\n",
      "Epoch 6/300\n",
      "6468/6468 [==============================] - 62s 10ms/step - loss: 9.9381 - val_loss: 8.7215\n",
      "Epoch 7/300\n",
      "6468/6468 [==============================] - 62s 10ms/step - loss: 9.0315 - val_loss: 8.4828\n",
      "Epoch 8/300\n",
      "6468/6468 [==============================] - 61s 9ms/step - loss: 8.1982 - val_loss: 7.9519\n",
      "Epoch 9/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.6260 - val_loss: 7.1909\n",
      "Epoch 10/300\n",
      "6468/6468 [==============================] - 62s 10ms/step - loss: 7.0394 - val_loss: 6.4869\n",
      "Epoch 11/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 6.5137 - val_loss: 6.2302\n",
      "Epoch 12/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 6.0391 - val_loss: 5.5687\n",
      "Epoch 13/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 5.5802 - val_loss: 5.2520\n",
      "Epoch 14/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 5.2232 - val_loss: 5.0041\n",
      "Epoch 15/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 4.8532 - val_loss: 4.6530\n",
      "Epoch 16/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 4.5023 - val_loss: 4.2441\n",
      "Epoch 17/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 4.1804 - val_loss: 3.8897\n",
      "Epoch 18/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 3.8338 - val_loss: 3.8379\n",
      "Epoch 19/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 3.6761 - val_loss: 3.6520\n",
      "Epoch 20/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 3.3886 - val_loss: 3.2804\n",
      "Epoch 21/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 3.1234 - val_loss: 3.1725\n",
      "Epoch 22/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 2.9311 - val_loss: 2.9504\n",
      "Epoch 23/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 2.7041 - val_loss: 2.7946\n",
      "Epoch 24/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 2.5976 - val_loss: 2.7568\n",
      "Epoch 25/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 2.4852 - val_loss: 2.5202\n",
      "Epoch 26/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 2.3442 - val_loss: 2.6761\n",
      "Epoch 27/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 2.1699 - val_loss: 2.5390\n",
      "Epoch 28/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 2.1262 - val_loss: 2.3281\n",
      "Epoch 29/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 1.9777 - val_loss: 2.4488\n",
      "Epoch 30/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 1.9485 - val_loss: 2.1722\n",
      "Epoch 31/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 1.7931 - val_loss: 2.1583\n",
      "Epoch 32/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 1.7863 - val_loss: 1.9039\n",
      "Epoch 33/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 1.6498 - val_loss: 1.9866\n",
      "Epoch 34/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 1.5731 - val_loss: 1.9304\n",
      "Epoch 35/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 1.5156 - val_loss: 1.7992\n",
      "Epoch 36/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 1.4204 - val_loss: 1.8116\n",
      "Epoch 37/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 1.4339 - val_loss: 1.8488\n",
      "Epoch 38/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 1.2918 - val_loss: 1.7706\n",
      "Epoch 39/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 1.2582 - val_loss: 1.6881\n",
      "Epoch 40/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 1.2251 - val_loss: 1.9179\n",
      "Epoch 41/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 1.2050 - val_loss: 1.4828\n",
      "Epoch 42/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 1.1563 - val_loss: 1.5440\n",
      "Epoch 43/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 1.1639 - val_loss: 1.4514\n",
      "Epoch 44/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 1.0566 - val_loss: 1.5382\n",
      "Epoch 45/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 1.0687 - val_loss: 1.3737\n",
      "Epoch 46/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.9977 - val_loss: 1.3778\n",
      "Epoch 47/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.9869 - val_loss: 1.3530\n",
      "Epoch 48/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.9855 - val_loss: 1.4291\n",
      "Epoch 49/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.9351 - val_loss: 1.3769\n",
      "Epoch 50/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.8959 - val_loss: 1.1858\n",
      "Epoch 51/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.9013 - val_loss: 1.2008\n",
      "Epoch 52/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.8962 - val_loss: 1.3715\n",
      "Epoch 53/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.8558 - val_loss: 1.2918\n",
      "Epoch 54/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.8389 - val_loss: 1.1762\n",
      "Epoch 55/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.8062 - val_loss: 1.2541\n",
      "Epoch 56/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.7778 - val_loss: 1.1575\n",
      "Epoch 57/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.7749 - val_loss: 1.2600\n",
      "Epoch 58/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.7268 - val_loss: 1.2239\n",
      "Epoch 59/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.7347 - val_loss: 1.1204\n",
      "Epoch 60/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.6839 - val_loss: 1.0979\n",
      "Epoch 61/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.6945 - val_loss: 1.0042\n",
      "Epoch 62/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.6790 - val_loss: 1.0136\n",
      "Epoch 63/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.6812 - val_loss: 1.1536\n",
      "Epoch 64/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.6548 - val_loss: 0.9492\n",
      "Epoch 65/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.6233 - val_loss: 0.9531\n",
      "Epoch 66/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.6291 - val_loss: 0.9076\n",
      "Epoch 67/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.6212 - val_loss: 0.9457\n",
      "Epoch 68/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.6075 - val_loss: 0.9500\n",
      "Epoch 69/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.5863 - val_loss: 0.9736\n",
      "Epoch 70/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.5932 - val_loss: 0.9734\n",
      "Epoch 71/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.5799 - val_loss: 0.9560\n",
      "Epoch 72/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.5840 - val_loss: 1.0710\n",
      "Epoch 73/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.5635 - val_loss: 0.8611\n",
      "Epoch 74/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.5552 - val_loss: 0.8368\n",
      "Epoch 75/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.5476 - val_loss: 0.8377\n",
      "Epoch 76/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.5688 - val_loss: 0.9158\n",
      "Epoch 77/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.5294 - val_loss: 0.9590\n",
      "Epoch 78/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.5178 - val_loss: 0.9088\n",
      "Epoch 79/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.5151 - val_loss: 1.0067\n",
      "Epoch 80/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.5053 - val_loss: 0.9969\n",
      "Epoch 81/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4874 - val_loss: 0.8496\n",
      "Epoch 82/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4987 - val_loss: 0.8359\n",
      "Epoch 83/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4749 - val_loss: 0.8356\n",
      "Epoch 84/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4840 - val_loss: 0.8200\n",
      "Epoch 85/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4849 - val_loss: 0.8770\n",
      "Epoch 86/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4548 - val_loss: 1.0444\n",
      "Epoch 87/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4960 - val_loss: 0.7844\n",
      "Epoch 88/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4724 - val_loss: 0.7629\n",
      "Epoch 89/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4466 - val_loss: 0.8469\n",
      "Epoch 90/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4379 - val_loss: 0.7333\n",
      "Epoch 91/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4538 - val_loss: 0.8184\n",
      "Epoch 92/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4522 - val_loss: 0.7299\n",
      "Epoch 93/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4319 - val_loss: 0.7147\n",
      "Epoch 94/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4301 - val_loss: 0.7337\n",
      "Epoch 95/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4321 - val_loss: 0.7765\n",
      "Epoch 96/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.4184 - val_loss: 0.8078\n",
      "Epoch 97/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.4116 - val_loss: 0.7564\n",
      "Epoch 98/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.4207 - val_loss: 0.7025\n",
      "Epoch 99/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.4047 - val_loss: 0.6992\n",
      "Epoch 100/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.4207 - val_loss: 0.7419\n",
      "Epoch 101/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.4099 - val_loss: 0.7435\n",
      "Epoch 102/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.4136 - val_loss: 0.8187\n",
      "Epoch 103/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3997 - val_loss: 0.7885\n",
      "Epoch 104/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.4170 - val_loss: 0.8187\n",
      "Epoch 105/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3826 - val_loss: 0.6576\n",
      "Epoch 106/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3842 - val_loss: 0.6898\n",
      "Epoch 107/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.4319 - val_loss: 0.8378\n",
      "Epoch 108/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3864 - val_loss: 0.8130\n",
      "Epoch 109/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3901 - val_loss: 0.8093\n",
      "Epoch 110/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3987 - val_loss: 0.8127\n",
      "Epoch 111/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3653 - val_loss: 0.7783\n",
      "Epoch 112/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3873 - val_loss: 0.6956\n",
      "Epoch 113/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3780 - val_loss: 0.7083\n",
      "Epoch 114/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3793 - val_loss: 0.6472\n",
      "Epoch 115/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3745 - val_loss: 0.6431\n",
      "Epoch 116/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3608 - val_loss: 0.7220\n",
      "Epoch 117/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3592 - val_loss: 0.7205\n",
      "Epoch 118/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3608 - val_loss: 0.7093\n",
      "Epoch 119/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3615 - val_loss: 0.7356\n",
      "Epoch 120/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3538 - val_loss: 0.7053\n",
      "Epoch 121/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3547 - val_loss: 0.6994\n",
      "Epoch 122/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3623 - val_loss: 0.6899\n",
      "Epoch 123/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3486 - val_loss: 0.6510\n",
      "Epoch 124/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3745 - val_loss: 0.6858\n",
      "Epoch 125/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3510 - val_loss: 0.6240\n",
      "Epoch 126/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3474 - val_loss: 0.7288\n",
      "Epoch 127/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3449 - val_loss: 0.8597\n",
      "Epoch 128/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3563 - val_loss: 0.6135\n",
      "Epoch 129/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3431 - val_loss: 0.7161\n",
      "Epoch 130/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3314 - val_loss: 0.6910\n",
      "Epoch 131/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3336 - val_loss: 0.8741\n",
      "Epoch 132/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3296 - val_loss: 0.6619\n",
      "Epoch 133/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3321 - val_loss: 0.8559\n",
      "Epoch 134/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3254 - val_loss: 0.6683\n",
      "Epoch 135/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3188 - val_loss: 0.6589\n",
      "Epoch 136/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3310 - val_loss: 0.6631\n",
      "Epoch 137/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3191 - val_loss: 0.6581\n",
      "Epoch 138/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3078 - val_loss: 0.6508\n",
      "Epoch 139/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3250 - val_loss: 0.6469\n",
      "Epoch 140/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3250 - val_loss: 0.6396\n",
      "Epoch 141/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3101 - val_loss: 0.6787\n",
      "Epoch 142/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3148 - val_loss: 0.6207\n",
      "Epoch 143/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3051 - val_loss: 0.6154\n",
      "Epoch 144/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2988 - val_loss: 0.5716\n",
      "Epoch 145/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3074 - val_loss: 0.6837\n",
      "Epoch 146/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3098 - val_loss: 0.5999\n",
      "Epoch 147/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3156 - val_loss: 0.6007\n",
      "Epoch 148/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.3018 - val_loss: 0.6593\n",
      "Epoch 149/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.3080 - val_loss: 0.6825\n",
      "Epoch 150/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.3067 - val_loss: 0.7174\n",
      "Epoch 151/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.3153 - val_loss: 0.6183\n",
      "Epoch 152/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.3006 - val_loss: 0.5805\n",
      "Epoch 153/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.3034 - val_loss: 0.6789\n",
      "Epoch 154/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2929 - val_loss: 0.6489\n",
      "Epoch 155/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.3017 - val_loss: 0.6254\n",
      "Epoch 156/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2918 - val_loss: 0.6136\n",
      "Epoch 157/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3025 - val_loss: 0.7625\n",
      "Epoch 158/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2928 - val_loss: 0.6780\n",
      "Epoch 159/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3072 - val_loss: 0.6050\n",
      "Epoch 160/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2960 - val_loss: 0.5979\n",
      "Epoch 161/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3061 - val_loss: 0.6091\n",
      "Epoch 162/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2814 - val_loss: 0.6188\n",
      "Epoch 163/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2938 - val_loss: 0.5830\n",
      "Epoch 164/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3070 - val_loss: 0.6113\n",
      "Epoch 165/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2894 - val_loss: 0.6457\n",
      "Epoch 166/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.3064 - val_loss: 0.6977\n",
      "Epoch 167/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2781 - val_loss: 0.6435\n",
      "Epoch 168/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2903 - val_loss: 0.6264\n",
      "Epoch 169/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2906 - val_loss: 0.6247\n",
      "Epoch 170/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2771 - val_loss: 0.6642\n",
      "Epoch 171/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2824 - val_loss: 0.6397\n",
      "Epoch 172/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2770 - val_loss: 0.6381\n",
      "Epoch 173/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2769 - val_loss: 0.7415\n",
      "Epoch 174/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2782 - val_loss: 0.6335\n",
      "Epoch 175/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2694 - val_loss: 0.6254\n",
      "Epoch 176/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2748 - val_loss: 0.5972\n",
      "Epoch 177/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2871 - val_loss: 0.6399\n",
      "Epoch 178/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2735 - val_loss: 0.6253\n",
      "Epoch 179/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2662 - val_loss: 0.5936\n",
      "Epoch 180/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2800 - val_loss: 0.6427\n",
      "Epoch 181/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2660 - val_loss: 0.7550\n",
      "Epoch 182/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2684 - val_loss: 0.6839\n",
      "Epoch 183/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2785 - val_loss: 0.5947\n",
      "Epoch 184/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2697 - val_loss: 0.6761\n",
      "Epoch 185/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2942 - val_loss: 0.6426\n",
      "Epoch 186/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2673 - val_loss: 0.6189\n",
      "Epoch 187/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2771 - val_loss: 0.6173\n",
      "Epoch 188/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2585 - val_loss: 0.5697\n",
      "Epoch 189/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2671 - val_loss: 0.6382\n",
      "Epoch 190/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2642 - val_loss: 0.6720\n",
      "Epoch 191/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2679 - val_loss: 0.5820\n",
      "Epoch 192/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2651 - val_loss: 0.6002\n",
      "Epoch 193/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2540 - val_loss: 0.8134\n",
      "Epoch 194/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2606 - val_loss: 0.6001\n",
      "Epoch 195/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2672 - val_loss: 0.6256\n",
      "Epoch 196/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2624 - val_loss: 0.6929\n",
      "Epoch 197/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2732 - val_loss: 0.6174\n",
      "Epoch 198/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2532 - val_loss: 0.6600\n",
      "Epoch 199/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2607 - val_loss: 0.6803\n",
      "Epoch 200/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2491 - val_loss: 0.6409\n",
      "Epoch 201/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2603 - val_loss: 0.7499\n",
      "Epoch 202/300\n",
      "6468/6468 [==============================] - 61s 9ms/step - loss: 0.2780 - val_loss: 0.6397\n",
      "Epoch 203/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2458 - val_loss: 0.6039\n",
      "Epoch 204/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2427 - val_loss: 0.6021\n",
      "Epoch 205/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2569 - val_loss: 0.6384\n",
      "Epoch 206/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2489 - val_loss: 0.5754\n",
      "Epoch 207/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2541 - val_loss: 0.6115\n",
      "Epoch 208/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2545 - val_loss: 0.5589\n",
      "Epoch 209/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2498 - val_loss: 0.7201\n",
      "Epoch 210/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2561 - val_loss: 0.6684\n",
      "Epoch 211/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2423 - val_loss: 0.6152\n",
      "Epoch 212/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2404 - val_loss: 0.5990\n",
      "Epoch 213/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2422 - val_loss: 0.6054\n",
      "Epoch 214/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2502 - val_loss: 0.6556\n",
      "Epoch 215/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2650 - val_loss: 0.6029\n",
      "Epoch 216/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2385 - val_loss: 0.5833\n",
      "Epoch 217/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2411 - val_loss: 0.6003\n",
      "Epoch 218/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2411 - val_loss: 0.6831\n",
      "Epoch 219/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2353 - val_loss: 0.6005\n",
      "Epoch 220/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2473 - val_loss: 0.6124\n",
      "Epoch 221/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2470 - val_loss: 0.6172\n",
      "Epoch 222/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2382 - val_loss: 0.6224\n",
      "Epoch 223/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2374 - val_loss: 0.5610\n",
      "Epoch 224/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 0.2404 - val_loss: 0.6165\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2391 - val_loss: 0.6042\n",
      "Epoch 226/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2470 - val_loss: 0.6437\n",
      "Epoch 227/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2366 - val_loss: 0.6230\n",
      "Epoch 228/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2380 - val_loss: 0.6478\n",
      "Epoch 229/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2694 - val_loss: 0.9192\n",
      "Epoch 230/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2418 - val_loss: 0.5771\n",
      "Epoch 231/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2319 - val_loss: 0.6040\n",
      "Epoch 232/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2626 - val_loss: 0.6098\n",
      "Epoch 233/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2353 - val_loss: 0.6165\n",
      "Epoch 234/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2350 - val_loss: 0.6144\n",
      "Epoch 235/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2301 - val_loss: 0.6511\n",
      "Epoch 236/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2303 - val_loss: 0.6557\n",
      "Epoch 237/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2364 - val_loss: 0.6485\n",
      "Epoch 238/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2356 - val_loss: 0.7204\n",
      "Epoch 239/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2275 - val_loss: 0.6236\n",
      "Epoch 240/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2302 - val_loss: 0.6050\n",
      "Epoch 241/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2294 - val_loss: 0.5466\n",
      "Epoch 242/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2328 - val_loss: 0.5971\n",
      "Epoch 243/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2369 - val_loss: 0.6788\n",
      "Epoch 244/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2201 - val_loss: 0.5895\n",
      "Epoch 245/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2313 - val_loss: 0.6280\n",
      "Epoch 246/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2301 - val_loss: 0.6079\n",
      "Epoch 247/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2349 - val_loss: 0.6606\n",
      "Epoch 248/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2226 - val_loss: 0.5910\n",
      "Epoch 249/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2290 - val_loss: 0.5959\n",
      "Epoch 250/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2154 - val_loss: 0.5984\n",
      "Epoch 251/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2275 - val_loss: 0.6074\n",
      "Epoch 252/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2170 - val_loss: 0.6260\n",
      "Epoch 253/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2190 - val_loss: 0.6510\n",
      "Epoch 254/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2255 - val_loss: 0.5870\n",
      "Epoch 255/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2178 - val_loss: 0.5885\n",
      "Epoch 256/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2182 - val_loss: 0.6191\n",
      "Epoch 257/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2512 - val_loss: 0.6351\n",
      "Epoch 258/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2147 - val_loss: 0.6284\n",
      "Epoch 259/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2219 - val_loss: 0.5866\n",
      "Epoch 260/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2227 - val_loss: 0.7463\n",
      "Epoch 261/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2210 - val_loss: 0.6169\n",
      "Epoch 262/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2214 - val_loss: 0.5707\n",
      "Epoch 263/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2219 - val_loss: 0.6540\n",
      "Epoch 264/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2145 - val_loss: 0.6064\n",
      "Epoch 265/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2196 - val_loss: 0.5511\n",
      "Epoch 266/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2146 - val_loss: 0.6030\n",
      "Epoch 267/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2100 - val_loss: 0.5882\n",
      "Epoch 268/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2120 - val_loss: 0.6081\n",
      "Epoch 269/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2128 - val_loss: 0.5916\n",
      "Epoch 270/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2080 - val_loss: 0.5958\n",
      "Epoch 271/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2131 - val_loss: 0.6073\n",
      "Epoch 272/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2143 - val_loss: 0.6293\n",
      "Epoch 273/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2153 - val_loss: 0.5797\n",
      "Epoch 274/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2131 - val_loss: 0.6772\n",
      "Epoch 275/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2098 - val_loss: 0.7509\n",
      "Epoch 276/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2193 - val_loss: 0.6091\n",
      "Epoch 277/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.1996 - val_loss: 0.5831\n",
      "Epoch 278/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2097 - val_loss: 0.5916\n",
      "Epoch 279/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2054 - val_loss: 0.5699\n",
      "Epoch 280/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2015 - val_loss: 0.5907\n",
      "Epoch 281/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2291 - val_loss: 0.5799\n",
      "Epoch 282/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2098 - val_loss: 0.6247\n",
      "Epoch 283/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2256 - val_loss: 0.6138\n",
      "Epoch 284/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2021 - val_loss: 0.5744\n",
      "Epoch 285/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2055 - val_loss: 0.6355\n",
      "Epoch 286/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2103 - val_loss: 0.6191\n",
      "Epoch 287/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2100 - val_loss: 0.6029\n",
      "Epoch 288/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2022 - val_loss: 0.6274\n",
      "Epoch 289/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2087 - val_loss: 0.5784\n",
      "Epoch 290/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2102 - val_loss: 0.5900\n",
      "Epoch 291/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2232 - val_loss: 0.5623\n",
      "Epoch 292/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2017 - val_loss: 0.5519\n",
      "Epoch 293/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2031 - val_loss: 0.6133\n",
      "Epoch 294/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2069 - val_loss: 0.5701\n",
      "Epoch 295/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2172 - val_loss: 0.6638\n",
      "Epoch 296/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2018 - val_loss: 0.5420\n",
      "Epoch 297/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.1977 - val_loss: 0.5478\n",
      "Epoch 298/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.1981 - val_loss: 0.5741\n",
      "Epoch 299/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2238 - val_loss: 0.6535\n",
      "Epoch 300/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 0.2163 - val_loss: 0.9379\n"
     ]
    }
   ],
   "source": [
    "hist = lstm_autoencoder.fit_generator(train_generator(x_train), epochs=300, steps_per_epoch=steps_per_epoch, verbose=1, validation_steps=len(x_val), validation_data=val_generator(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = lstm_autoencoder.to_json()\n",
    "filename = 'last_mse_lstmae' # input('filename: ') #\n",
    "with open('model_save/mse_weights/' + filename + '.json', 'w') as file:\n",
    "    file.write(model_json)\n",
    "lstm_autoencoder.save_weights('model_save/mse_weights/weights_' +  filename + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('model_save/mse_weights/mse_history.json', 'w') as f:\n",
    "    json.dump(hist.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "loss_ax.plot(hist.history['val_loss'], 'b', label='val l')\n",
    "loss_ax.plot(hist.history['loss'], 'r', label='train loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.title('mse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1010 15:48:40.110543 140189195294464 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1010 15:48:40.120297 140189195294464 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1010 15:48:40.123097 140189195294464 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1010 15:48:40.688915 140189195294464 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1010 15:48:40.689456 140189195294464 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"last_mse_lstmae\"\n",
    "loaded_model = model_from_json(open('model_save/mse_weights/' +filename + '.json').read())\n",
    "loaded_model.load_weights('model_save/mse_weights/weights_' + filename + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = lstm_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9947123981856851\n"
     ]
    }
   ],
   "source": [
    "mean= 0\n",
    "for xt in x_test:\n",
    "    xt = xt.reshape(1, xt.shape[0], xt.shape[1])\n",
    "    out = loaded_model.predict(xt)\n",
    "    mean += ((xt-out)**2).mean(axis=None)\n",
    "print(mean/len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(loaded_model.input, loaded_model.layers[3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = x_test[0].reshape(1, x_test[0].shape[0], x_test[0].shape[1])\n",
    "latent_vector = []\n",
    "for x in x_test:\n",
    "    x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "    latent_vector.append(encoder.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_save/mse_weights/weights' + '{epoch:02d}-{loss:.4f}.h5'\n",
    "early_stopping_callback = EarlyStopping(monitor='loss', patience=200)\n",
    "checkpoint_callback = ModelCheckpoint(model_path, monitor='loss', verbose = 1, save_best_only = True, save_weights_only = True, mode='min')#, period=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def train_generator(x_train):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        leng = len(x_train[idx])\n",
    "        dt = [x_train[idx]]\n",
    "        while(leng == len(x_train[idx+1]) and idx < len(x_train)):\n",
    "            dt += [x_train[idx+1]]\n",
    "            idx += 1\n",
    "            if len(dt) >= 100:\n",
    "                break\n",
    "        yield np.array(dt), np.array(dt)\n",
    "        if idx >= len(x_train):\n",
    "            break\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
