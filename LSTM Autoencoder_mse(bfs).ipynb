{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob, os\n",
    "from keras import layers as ly\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Lambda\n",
    "from keras import losses\n",
    "from keras.models import model_from_json\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir = './sequence/*'\n",
    "dir = './latest_sequence/bfs-character/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file read\n",
    "name = []\n",
    "all_data = []\n",
    "sequence_length = []\n",
    "alpha = list(string.ascii_uppercase)\n",
    "for file in sorted(glob.glob(dir)):\n",
    "    name.append(file.split('/')[-1].replace('.txt', ''))\n",
    "    datasets = []\n",
    "    for f in open(file, 'r'):\n",
    "        f = f.replace(']', '').replace('[', '').replace('\\n','')\n",
    "        (u, v, w) = f.split(', ')\n",
    "        datasets.append([alpha.index(u[1])+1, alpha.index(v[1]) +1, float(w)])\n",
    "    sequence_length.append(len(datasets))\n",
    "    all_data.append(datasets)\n",
    "#all_data = np.array(all_data)\n",
    "all_data = np.array([np.array(arr) for arr in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, train_name, test_name = train_test_split(all_data, name, test_size=0.3)\n",
    "x_test, x_val, test_name, val_name = train_test_split(x_test, test_name, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name\n",
    "tr_names= []\n",
    "for name in train_name:\n",
    "    tr_names.append(name.split('-')[0].replace('graph', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max(sequence_length)\n",
    "n_features = 3\n",
    "batch_size = 32\n",
    "epochs = 500\n",
    "steps_per_epoch = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    loss1 = losses.mean_squared_error(y_true, y_pred)\n",
    "    #loss2 = losses.kld(y_true, y_pred)\n",
    "    return loss1# * 0.7 + loss2 * 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1007 23:51:24.764862 139985173763840 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1007 23:51:24.788869 139985173763840 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1007 23:51:24.794222 139985173763840 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1007 23:51:25.861754 139985173763840 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def repeat_vector(args):\n",
    "    layer_to_repeat = args[0]\n",
    "    sequence_layer = args[1]\n",
    "    return RepeatVector(K.shape(sequence_layer)[1])(layer_to_repeat)\n",
    "    \n",
    "\n",
    "inputs = Input(shape=(None, 3))\n",
    "encoded = LSTM(128, return_sequences=True)(inputs)  #activation 안적으면 tanh\n",
    "encoded = LSTM(64)(encoded)\n",
    "\n",
    "decoded = Lambda(repeat_vector, output_shape=(None, 64)) ([encoded, inputs]) # inputs의 shape[1] 만큼 encoded 를 반복 생성\n",
    "\n",
    "decoded = LSTM(64, return_sequences=True)(decoded)\n",
    "decoded = LSTM(128, return_sequences=True)(decoded)\n",
    "decoded = TimeDistributed(Dense(3))(decoded)\n",
    "encoder = Model(inputs, encoded)\n",
    "\n",
    "lstm_autoencoder = Model(inputs, decoded)\n",
    "lstm_autoencoder.compile(loss=losses.mean_squared_error, optimizer='adam')\n",
    "#lstm_autoencoder_500 = lstm_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(x_train):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        yield np.array([x_train[idx]]), np.array([x_train[idx]])\n",
    "        idx +=1\n",
    "        if idx >= len(x_train):\n",
    "            idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_save/mse_weights/weights' + '{epoch:02d}-{loss:.4f}.h5'\n",
    "early_stopping_callback = EarlyStopping(monitor='loss', patience=200)\n",
    "checkpoint_callback = ModelCheckpoint(model_path, monitor='loss', verbose = 1, save_best_only = True, save_weights_only = True, mode='min')#, period=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2360/2360 [==============================] - 76s 32ms/step - loss: 37.1500\n",
      "\n",
      "Epoch 00001: loss improved from inf to 37.14996, saving model to result/mse_weights/weights01-37.1500.h5\n",
      "Epoch 2/500\n",
      "2360/2360 [==============================] - 63s 27ms/step - loss: 37.1118\n",
      "\n",
      "Epoch 00002: loss improved from 37.14996 to 37.11185, saving model to result/mse_weights/weights02-37.1118.h5\n",
      "Epoch 3/500\n",
      "2360/2360 [==============================] - 46s 19ms/step - loss: 37.0955\n",
      "\n",
      "Epoch 00003: loss improved from 37.11185 to 37.09550, saving model to result/mse_weights/weights03-37.0955.h5\n",
      "Epoch 4/500\n",
      "2360/2360 [==============================] - 39s 16ms/step - loss: 37.0872\n",
      "\n",
      "Epoch 00004: loss improved from 37.09550 to 37.08720, saving model to result/mse_weights/weights04-37.0872.h5\n",
      "Epoch 5/500\n",
      "2360/2360 [==============================] - 48s 20ms/step - loss: 37.0588\n",
      "\n",
      "Epoch 00005: loss improved from 37.08720 to 37.05875, saving model to result/mse_weights/weights05-37.0588.h5\n",
      "Epoch 6/500\n",
      "2360/2360 [==============================] - 47s 20ms/step - loss: 19.1424\n",
      "\n",
      "Epoch 00006: loss improved from 37.05875 to 19.14236, saving model to result/mse_weights/weights06-19.1424.h5\n",
      "Epoch 7/500\n",
      "2360/2360 [==============================] - 44s 19ms/step - loss: 13.5967\n",
      "\n",
      "Epoch 00007: loss improved from 19.14236 to 13.59671, saving model to result/mse_weights/weights07-13.5967.h5\n",
      "Epoch 8/500\n",
      "2360/2360 [==============================] - 42s 18ms/step - loss: 11.9328\n",
      "\n",
      "Epoch 00008: loss improved from 13.59671 to 11.93284, saving model to result/mse_weights/weights08-11.9328.h5\n",
      "Epoch 9/500\n",
      "2360/2360 [==============================] - 45s 19ms/step - loss: 10.8514\n",
      "\n",
      "Epoch 00009: loss improved from 11.93284 to 10.85141, saving model to result/mse_weights/weights09-10.8514.h5\n",
      "Epoch 10/500\n",
      "2360/2360 [==============================] - 41s 17ms/step - loss: 9.9730\n",
      "\n",
      "Epoch 00010: loss improved from 10.85141 to 9.97303, saving model to result/mse_weights/weights10-9.9730.h5\n",
      "Epoch 11/500\n",
      "2360/2360 [==============================] - 48s 20ms/step - loss: 8.6831\n",
      "\n",
      "Epoch 00011: loss improved from 9.97303 to 8.68312, saving model to result/mse_weights/weights11-8.6831.h5\n",
      "Epoch 12/500\n",
      "2360/2360 [==============================] - 40s 17ms/step - loss: 7.4642\n",
      "\n",
      "Epoch 00012: loss improved from 8.68312 to 7.46422, saving model to result/mse_weights/weights12-7.4642.h5\n",
      "Epoch 13/500\n",
      "2360/2360 [==============================] - 42s 18ms/step - loss: 6.9764\n",
      "\n",
      "Epoch 00013: loss improved from 7.46422 to 6.97637, saving model to result/mse_weights/weights13-6.9764.h5\n",
      "Epoch 14/500\n",
      "2360/2360 [==============================] - 37s 16ms/step - loss: 6.3727\n",
      "\n",
      "Epoch 00014: loss improved from 6.97637 to 6.37269, saving model to result/mse_weights/weights14-6.3727.h5\n",
      "Epoch 15/500\n",
      "2360/2360 [==============================] - 37s 16ms/step - loss: 5.9728\n",
      "\n",
      "Epoch 00015: loss improved from 6.37269 to 5.97282, saving model to result/mse_weights/weights15-5.9728.h5\n",
      "Epoch 16/500\n",
      "2360/2360 [==============================] - 42s 18ms/step - loss: 5.6629\n",
      "\n",
      "Epoch 00016: loss improved from 5.97282 to 5.66285, saving model to result/mse_weights/weights16-5.6629.h5\n",
      "Epoch 17/500\n",
      "2360/2360 [==============================] - 41s 17ms/step - loss: 5.1393\n",
      "\n",
      "Epoch 00017: loss improved from 5.66285 to 5.13931, saving model to result/mse_weights/weights17-5.1393.h5\n",
      "Epoch 18/500\n",
      "2360/2360 [==============================] - 45s 19ms/step - loss: 5.2066\n",
      "\n",
      "Epoch 00018: loss did not improve from 5.13931\n",
      "Epoch 19/500\n",
      "2360/2360 [==============================] - 39s 17ms/step - loss: 4.7414\n",
      "\n",
      "Epoch 00019: loss improved from 5.13931 to 4.74141, saving model to result/mse_weights/weights19-4.7414.h5\n",
      "Epoch 20/500\n",
      "2360/2360 [==============================] - 38s 16ms/step - loss: 4.4788\n",
      "\n",
      "Epoch 00020: loss improved from 4.74141 to 4.47884, saving model to result/mse_weights/weights20-4.4788.h5\n",
      "Epoch 21/500\n",
      "2360/2360 [==============================] - 38s 16ms/step - loss: 4.1375\n",
      "\n",
      "Epoch 00021: loss improved from 4.47884 to 4.13750, saving model to result/mse_weights/weights21-4.1375.h5\n",
      "Epoch 22/500\n",
      "2360/2360 [==============================] - 38s 16ms/step - loss: 3.9997\n",
      "\n",
      "Epoch 00022: loss improved from 4.13750 to 3.99973, saving model to result/mse_weights/weights22-3.9997.h5\n",
      "Epoch 23/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 4.3605\n",
      "\n",
      "Epoch 00023: loss did not improve from 3.99973\n",
      "Epoch 24/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 4.4381\n",
      "\n",
      "Epoch 00024: loss did not improve from 3.99973\n",
      "Epoch 25/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 3.9963\n",
      "\n",
      "Epoch 00025: loss improved from 3.99973 to 3.99633, saving model to result/mse_weights/weights25-3.9963.h5\n",
      "Epoch 26/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 3.7297\n",
      "\n",
      "Epoch 00026: loss improved from 3.99633 to 3.72968, saving model to result/mse_weights/weights26-3.7297.h5\n",
      "Epoch 27/500\n",
      "2360/2360 [==============================] - 37s 16ms/step - loss: 3.7696\n",
      "\n",
      "Epoch 00027: loss did not improve from 3.72968\n",
      "Epoch 28/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 3.4312\n",
      "\n",
      "Epoch 00028: loss improved from 3.72968 to 3.43124, saving model to result/mse_weights/weights28-3.4312.h5\n",
      "Epoch 29/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 3.3508\n",
      "\n",
      "Epoch 00029: loss improved from 3.43124 to 3.35076, saving model to result/mse_weights/weights29-3.3508.h5\n",
      "Epoch 30/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 3.1036\n",
      "\n",
      "Epoch 00030: loss improved from 3.35076 to 3.10363, saving model to result/mse_weights/weights30-3.1036.h5\n",
      "Epoch 31/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 3.4229\n",
      "\n",
      "Epoch 00031: loss did not improve from 3.10363\n",
      "Epoch 32/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 3.2632\n",
      "\n",
      "Epoch 00032: loss did not improve from 3.10363\n",
      "Epoch 33/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 2.8723\n",
      "\n",
      "Epoch 00033: loss improved from 3.10363 to 2.87230, saving model to result/mse_weights/weights33-2.8723.h5\n",
      "Epoch 34/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 2.7858\n",
      "\n",
      "Epoch 00034: loss improved from 2.87230 to 2.78577, saving model to result/mse_weights/weights34-2.7858.h5\n",
      "Epoch 35/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 2.8723\n",
      "\n",
      "Epoch 00035: loss did not improve from 2.78577\n",
      "Epoch 36/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 2.9337\n",
      "\n",
      "Epoch 00036: loss did not improve from 2.78577\n",
      "Epoch 37/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 2.7504\n",
      "\n",
      "Epoch 00037: loss improved from 2.78577 to 2.75039, saving model to result/mse_weights/weights37-2.7504.h5\n",
      "Epoch 38/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 2.7332\n",
      "\n",
      "Epoch 00038: loss improved from 2.75039 to 2.73320, saving model to result/mse_weights/weights38-2.7332.h5\n",
      "Epoch 39/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 2.5033\n",
      "\n",
      "Epoch 00039: loss improved from 2.73320 to 2.50325, saving model to result/mse_weights/weights39-2.5033.h5\n",
      "Epoch 40/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 2.6253\n",
      "\n",
      "Epoch 00040: loss did not improve from 2.50325\n",
      "Epoch 41/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 2.2496\n",
      "\n",
      "Epoch 00041: loss improved from 2.50325 to 2.24958, saving model to result/mse_weights/weights41-2.2496.h5\n",
      "Epoch 42/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 2.3580\n",
      "\n",
      "Epoch 00042: loss did not improve from 2.24958\n",
      "Epoch 43/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 2.2989\n",
      "\n",
      "Epoch 00043: loss did not improve from 2.24958\n",
      "Epoch 44/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 2.2424\n",
      "\n",
      "Epoch 00044: loss improved from 2.24958 to 2.24238, saving model to result/mse_weights/weights44-2.2424.h5\n",
      "Epoch 45/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 2.2394\n",
      "\n",
      "Epoch 00045: loss improved from 2.24238 to 2.23937, saving model to result/mse_weights/weights45-2.2394.h5\n",
      "Epoch 46/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 2.4736\n",
      "\n",
      "Epoch 00046: loss did not improve from 2.23937\n",
      "Epoch 47/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 2.5349\n",
      "\n",
      "Epoch 00047: loss did not improve from 2.23937\n",
      "Epoch 48/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 2.0145\n",
      "\n",
      "Epoch 00048: loss improved from 2.23937 to 2.01446, saving model to result/mse_weights/weights48-2.0145.h5\n",
      "Epoch 49/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.9812\n",
      "\n",
      "Epoch 00049: loss improved from 2.01446 to 1.98116, saving model to result/mse_weights/weights49-1.9812.h5\n",
      "Epoch 50/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.9076\n",
      "\n",
      "Epoch 00050: loss improved from 1.98116 to 1.90762, saving model to result/mse_weights/weights50-1.9076.h5\n",
      "Epoch 51/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.9089\n",
      "\n",
      "Epoch 00051: loss did not improve from 1.90762\n",
      "Epoch 52/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 2.0327\n",
      "\n",
      "Epoch 00052: loss did not improve from 1.90762\n",
      "Epoch 53/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.9802\n",
      "\n",
      "Epoch 00053: loss did not improve from 1.90762\n",
      "Epoch 54/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 2.0175\n",
      "\n",
      "Epoch 00054: loss did not improve from 1.90762\n",
      "Epoch 55/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 1.6871\n",
      "\n",
      "Epoch 00055: loss improved from 1.90762 to 1.68713, saving model to result/mse_weights/weights55-1.6871.h5\n",
      "Epoch 56/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 2.0234\n",
      "\n",
      "Epoch 00056: loss did not improve from 1.68713\n",
      "Epoch 57/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 1.5256\n",
      "\n",
      "Epoch 00057: loss improved from 1.68713 to 1.52557, saving model to result/mse_weights/weights57-1.5256.h5\n",
      "Epoch 58/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.7740\n",
      "\n",
      "Epoch 00058: loss did not improve from 1.52557\n",
      "Epoch 59/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 1.5206\n",
      "\n",
      "Epoch 00059: loss improved from 1.52557 to 1.52063, saving model to result/mse_weights/weights59-1.5206.h5\n",
      "Epoch 60/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.7784\n",
      "\n",
      "Epoch 00060: loss did not improve from 1.52063\n",
      "Epoch 61/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 1.5947\n",
      "\n",
      "Epoch 00061: loss did not improve from 1.52063\n",
      "Epoch 62/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.4917\n",
      "\n",
      "Epoch 00062: loss improved from 1.52063 to 1.49168, saving model to result/mse_weights/weights62-1.4917.h5\n",
      "Epoch 63/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.7222\n",
      "\n",
      "Epoch 00063: loss did not improve from 1.49168\n",
      "Epoch 64/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.3114\n",
      "\n",
      "Epoch 00064: loss improved from 1.49168 to 1.31143, saving model to result/mse_weights/weights64-1.3114.h5\n",
      "Epoch 65/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.6834\n",
      "\n",
      "Epoch 00065: loss did not improve from 1.31143\n",
      "Epoch 66/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.5657\n",
      "\n",
      "Epoch 00066: loss did not improve from 1.31143\n",
      "Epoch 67/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.4014\n",
      "\n",
      "Epoch 00067: loss did not improve from 1.31143\n",
      "Epoch 68/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.2231\n",
      "\n",
      "Epoch 00068: loss improved from 1.31143 to 1.22306, saving model to result/mse_weights/weights68-1.2231.h5\n",
      "Epoch 69/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.3336\n",
      "\n",
      "Epoch 00069: loss did not improve from 1.22306\n",
      "Epoch 70/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 1.3283\n",
      "\n",
      "Epoch 00070: loss did not improve from 1.22306\n",
      "Epoch 71/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 1.1546\n",
      "\n",
      "Epoch 00071: loss improved from 1.22306 to 1.15461, saving model to result/mse_weights/weights71-1.1546.h5\n",
      "Epoch 72/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 1.3447\n",
      "\n",
      "Epoch 00072: loss did not improve from 1.15461\n",
      "Epoch 73/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.9686\n",
      "\n",
      "Epoch 00073: loss improved from 1.15461 to 0.96857, saving model to result/mse_weights/weights73-0.9686.h5\n",
      "Epoch 74/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.2355\n",
      "\n",
      "Epoch 00074: loss did not improve from 0.96857\n",
      "Epoch 75/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 1.2624\n",
      "\n",
      "Epoch 00075: loss did not improve from 0.96857\n",
      "Epoch 76/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.0735\n",
      "\n",
      "Epoch 00076: loss did not improve from 0.96857\n",
      "Epoch 77/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.1853\n",
      "\n",
      "Epoch 00077: loss did not improve from 0.96857\n",
      "Epoch 78/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.1668\n",
      "\n",
      "Epoch 00078: loss did not improve from 0.96857\n",
      "Epoch 79/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.1224\n",
      "\n",
      "Epoch 00079: loss did not improve from 0.96857\n",
      "Epoch 80/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.2342\n",
      "\n",
      "Epoch 00080: loss did not improve from 0.96857\n",
      "Epoch 81/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.2495\n",
      "\n",
      "Epoch 00081: loss did not improve from 0.96857\n",
      "Epoch 82/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.8900\n",
      "\n",
      "Epoch 00082: loss improved from 0.96857 to 0.89004, saving model to result/mse_weights/weights82-0.8900.h5\n",
      "Epoch 83/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 1.1079\n",
      "\n",
      "Epoch 00083: loss did not improve from 0.89004\n",
      "Epoch 84/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 1.0399\n",
      "\n",
      "Epoch 00084: loss did not improve from 0.89004\n",
      "Epoch 85/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.9543\n",
      "\n",
      "Epoch 00085: loss did not improve from 0.89004\n",
      "Epoch 86/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.9631\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.89004\n",
      "Epoch 87/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.8190\n",
      "\n",
      "Epoch 00087: loss improved from 0.89004 to 0.81896, saving model to result/mse_weights/weights87-0.8190.h5\n",
      "Epoch 88/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.7919\n",
      "\n",
      "Epoch 00088: loss improved from 0.81896 to 0.79195, saving model to result/mse_weights/weights88-0.7919.h5\n",
      "Epoch 89/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 1.0961\n",
      "\n",
      "Epoch 00089: loss did not improve from 0.79195\n",
      "Epoch 90/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.6326\n",
      "\n",
      "Epoch 00090: loss improved from 0.79195 to 0.63263, saving model to result/mse_weights/weights90-0.6326.h5\n",
      "Epoch 91/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.6689\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.63263\n",
      "Epoch 92/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.8740\n",
      "\n",
      "Epoch 00092: loss did not improve from 0.63263\n",
      "Epoch 93/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.7652\n",
      "\n",
      "Epoch 00093: loss did not improve from 0.63263\n",
      "Epoch 94/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.9457\n",
      "\n",
      "Epoch 00094: loss did not improve from 0.63263\n",
      "Epoch 95/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.8655\n",
      "\n",
      "Epoch 00095: loss did not improve from 0.63263\n",
      "Epoch 96/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.6786\n",
      "\n",
      "Epoch 00096: loss did not improve from 0.63263\n",
      "Epoch 97/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.6365\n",
      "\n",
      "Epoch 00097: loss did not improve from 0.63263\n",
      "Epoch 98/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.7458\n",
      "\n",
      "Epoch 00098: loss did not improve from 0.63263\n",
      "Epoch 99/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.7281\n",
      "\n",
      "Epoch 00099: loss did not improve from 0.63263\n",
      "Epoch 100/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.7549\n",
      "\n",
      "Epoch 00100: loss did not improve from 0.63263\n",
      "Epoch 101/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.7406\n",
      "\n",
      "Epoch 00101: loss did not improve from 0.63263\n",
      "Epoch 102/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.6796\n",
      "\n",
      "Epoch 00102: loss did not improve from 0.63263\n",
      "Epoch 103/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.6602\n",
      "\n",
      "Epoch 00103: loss did not improve from 0.63263\n",
      "Epoch 104/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.6246\n",
      "\n",
      "Epoch 00104: loss improved from 0.63263 to 0.62464, saving model to result/mse_weights/weights104-0.6246.h5\n",
      "Epoch 105/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.5552\n",
      "\n",
      "Epoch 00105: loss improved from 0.62464 to 0.55523, saving model to result/mse_weights/weights105-0.5552.h5\n",
      "Epoch 106/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.6670\n",
      "\n",
      "Epoch 00106: loss did not improve from 0.55523\n",
      "Epoch 107/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.6252\n",
      "\n",
      "Epoch 00107: loss did not improve from 0.55523\n",
      "Epoch 108/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.7778\n",
      "\n",
      "Epoch 00108: loss did not improve from 0.55523\n",
      "Epoch 109/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.6001\n",
      "\n",
      "Epoch 00109: loss did not improve from 0.55523\n",
      "Epoch 110/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.5147\n",
      "\n",
      "Epoch 00110: loss improved from 0.55523 to 0.51466, saving model to result/mse_weights/weights110-0.5147.h5\n",
      "Epoch 111/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.4654\n",
      "\n",
      "Epoch 00111: loss improved from 0.51466 to 0.46542, saving model to result/mse_weights/weights111-0.4654.h5\n",
      "Epoch 112/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.6859\n",
      "\n",
      "Epoch 00112: loss did not improve from 0.46542\n",
      "Epoch 113/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.7227\n",
      "\n",
      "Epoch 00113: loss did not improve from 0.46542\n",
      "Epoch 114/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.5760\n",
      "\n",
      "Epoch 00114: loss did not improve from 0.46542\n",
      "Epoch 115/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.6188\n",
      "\n",
      "Epoch 00115: loss did not improve from 0.46542\n",
      "Epoch 116/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.5416\n",
      "\n",
      "Epoch 00116: loss did not improve from 0.46542\n",
      "Epoch 117/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.4466\n",
      "\n",
      "Epoch 00117: loss improved from 0.46542 to 0.44661, saving model to result/mse_weights/weights117-0.4466.h5\n",
      "Epoch 118/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.4436\n",
      "\n",
      "Epoch 00118: loss improved from 0.44661 to 0.44363, saving model to result/mse_weights/weights118-0.4436.h5\n",
      "Epoch 119/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.4991\n",
      "\n",
      "Epoch 00119: loss did not improve from 0.44363\n",
      "Epoch 120/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.3636\n",
      "\n",
      "Epoch 00120: loss improved from 0.44363 to 0.36361, saving model to result/mse_weights/weights120-0.3636.h5\n",
      "Epoch 121/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.4162\n",
      "\n",
      "Epoch 00121: loss did not improve from 0.36361\n",
      "Epoch 122/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.3955\n",
      "\n",
      "Epoch 00122: loss did not improve from 0.36361\n",
      "Epoch 123/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.3727\n",
      "\n",
      "Epoch 00123: loss did not improve from 0.36361\n",
      "Epoch 124/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.3730\n",
      "\n",
      "Epoch 00124: loss did not improve from 0.36361\n",
      "Epoch 125/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.7414\n",
      "\n",
      "Epoch 00125: loss did not improve from 0.36361\n",
      "Epoch 126/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.5088\n",
      "\n",
      "Epoch 00126: loss did not improve from 0.36361\n",
      "Epoch 127/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.4542\n",
      "\n",
      "Epoch 00127: loss did not improve from 0.36361\n",
      "Epoch 128/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.3634\n",
      "\n",
      "Epoch 00128: loss improved from 0.36361 to 0.36335, saving model to result/mse_weights/weights128-0.3634.h5\n",
      "Epoch 129/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.4933\n",
      "\n",
      "Epoch 00129: loss did not improve from 0.36335\n",
      "Epoch 130/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.3960\n",
      "\n",
      "Epoch 00130: loss did not improve from 0.36335\n",
      "Epoch 131/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.3460\n",
      "\n",
      "Epoch 00131: loss improved from 0.36335 to 0.34599, saving model to result/mse_weights/weights131-0.3460.h5\n",
      "Epoch 132/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.3241\n",
      "\n",
      "Epoch 00132: loss improved from 0.34599 to 0.32411, saving model to result/mse_weights/weights132-0.3241.h5\n",
      "Epoch 133/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.3260\n",
      "\n",
      "Epoch 00133: loss did not improve from 0.32411\n",
      "Epoch 134/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.3348\n",
      "\n",
      "Epoch 00134: loss did not improve from 0.32411\n",
      "Epoch 135/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.4459\n",
      "\n",
      "Epoch 00135: loss did not improve from 0.32411\n",
      "Epoch 136/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.3079\n",
      "\n",
      "Epoch 00136: loss improved from 0.32411 to 0.30789, saving model to result/mse_weights/weights136-0.3079.h5\n",
      "Epoch 137/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2599\n",
      "\n",
      "Epoch 00137: loss improved from 0.30789 to 0.25986, saving model to result/mse_weights/weights137-0.2599.h5\n",
      "Epoch 138/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.4416\n",
      "\n",
      "Epoch 00138: loss did not improve from 0.25986\n",
      "Epoch 139/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.6446\n",
      "\n",
      "Epoch 00139: loss did not improve from 0.25986\n",
      "Epoch 140/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.4209\n",
      "\n",
      "Epoch 00140: loss did not improve from 0.25986\n",
      "Epoch 141/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.2349\n",
      "\n",
      "Epoch 00141: loss improved from 0.25986 to 0.23488, saving model to result/mse_weights/weights141-0.2349.h5\n",
      "Epoch 142/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.3245\n",
      "\n",
      "Epoch 00142: loss did not improve from 0.23488\n",
      "Epoch 143/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.4069\n",
      "\n",
      "Epoch 00143: loss did not improve from 0.23488\n",
      "Epoch 144/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2792\n",
      "\n",
      "Epoch 00144: loss did not improve from 0.23488\n",
      "Epoch 145/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.3717\n",
      "\n",
      "Epoch 00145: loss did not improve from 0.23488\n",
      "Epoch 146/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.3218\n",
      "\n",
      "Epoch 00146: loss did not improve from 0.23488\n",
      "Epoch 147/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.2544\n",
      "\n",
      "Epoch 00147: loss did not improve from 0.23488\n",
      "Epoch 148/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.2757\n",
      "\n",
      "Epoch 00148: loss did not improve from 0.23488\n",
      "Epoch 149/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.2943\n",
      "\n",
      "Epoch 00149: loss did not improve from 0.23488\n",
      "Epoch 150/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.2837\n",
      "\n",
      "Epoch 00150: loss did not improve from 0.23488\n",
      "Epoch 151/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2726\n",
      "\n",
      "Epoch 00151: loss did not improve from 0.23488\n",
      "Epoch 152/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.2660\n",
      "\n",
      "Epoch 00152: loss did not improve from 0.23488\n",
      "Epoch 153/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2434\n",
      "\n",
      "Epoch 00153: loss did not improve from 0.23488\n",
      "Epoch 154/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.2450\n",
      "\n",
      "Epoch 00154: loss did not improve from 0.23488\n",
      "Epoch 155/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2915\n",
      "\n",
      "Epoch 00155: loss did not improve from 0.23488\n",
      "Epoch 156/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2285\n",
      "\n",
      "Epoch 00156: loss improved from 0.23488 to 0.22847, saving model to result/mse_weights/weights156-0.2285.h5\n",
      "Epoch 157/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2468\n",
      "\n",
      "Epoch 00157: loss did not improve from 0.22847\n",
      "Epoch 158/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2261\n",
      "\n",
      "Epoch 00158: loss improved from 0.22847 to 0.22609, saving model to result/mse_weights/weights158-0.2261.h5\n",
      "Epoch 159/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2235\n",
      "\n",
      "Epoch 00159: loss improved from 0.22609 to 0.22349, saving model to result/mse_weights/weights159-0.2235.h5\n",
      "Epoch 160/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2307\n",
      "\n",
      "Epoch 00160: loss did not improve from 0.22349\n",
      "Epoch 161/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2572\n",
      "\n",
      "Epoch 00161: loss did not improve from 0.22349\n",
      "Epoch 162/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1996\n",
      "\n",
      "Epoch 00162: loss improved from 0.22349 to 0.19956, saving model to result/mse_weights/weights162-0.1996.h5\n",
      "Epoch 163/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2294\n",
      "\n",
      "Epoch 00163: loss did not improve from 0.19956\n",
      "Epoch 164/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.2724\n",
      "\n",
      "Epoch 00164: loss did not improve from 0.19956\n",
      "Epoch 165/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.3760\n",
      "\n",
      "Epoch 00165: loss did not improve from 0.19956\n",
      "Epoch 166/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.3499\n",
      "\n",
      "Epoch 00166: loss did not improve from 0.19956\n",
      "Epoch 167/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.3311\n",
      "\n",
      "Epoch 00167: loss did not improve from 0.19956\n",
      "Epoch 168/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2295\n",
      "\n",
      "Epoch 00168: loss did not improve from 0.19956\n",
      "Epoch 169/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1777\n",
      "\n",
      "Epoch 00169: loss improved from 0.19956 to 0.17768, saving model to result/mse_weights/weights169-0.1777.h5\n",
      "Epoch 170/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2153\n",
      "\n",
      "Epoch 00170: loss did not improve from 0.17768\n",
      "Epoch 171/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2129\n",
      "\n",
      "Epoch 00171: loss did not improve from 0.17768\n",
      "Epoch 172/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.3105\n",
      "\n",
      "Epoch 00172: loss did not improve from 0.17768\n",
      "Epoch 173/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1820\n",
      "\n",
      "Epoch 00173: loss did not improve from 0.17768\n",
      "Epoch 174/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1948\n",
      "\n",
      "Epoch 00174: loss did not improve from 0.17768\n",
      "Epoch 175/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1991\n",
      "\n",
      "Epoch 00175: loss did not improve from 0.17768\n",
      "Epoch 176/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1973\n",
      "\n",
      "Epoch 00176: loss did not improve from 0.17768\n",
      "Epoch 177/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.2072\n",
      "\n",
      "Epoch 00177: loss did not improve from 0.17768\n",
      "Epoch 178/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.3158\n",
      "\n",
      "Epoch 00178: loss did not improve from 0.17768\n",
      "Epoch 179/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2218\n",
      "\n",
      "Epoch 00179: loss did not improve from 0.17768\n",
      "Epoch 180/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1738\n",
      "\n",
      "Epoch 00180: loss improved from 0.17768 to 0.17384, saving model to result/mse_weights/weights180-0.1738.h5\n",
      "Epoch 181/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1742\n",
      "\n",
      "Epoch 00181: loss did not improve from 0.17384\n",
      "Epoch 182/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1919\n",
      "\n",
      "Epoch 00182: loss did not improve from 0.17384\n",
      "Epoch 183/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1862\n",
      "\n",
      "Epoch 00183: loss did not improve from 0.17384\n",
      "Epoch 184/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1896\n",
      "\n",
      "Epoch 00184: loss did not improve from 0.17384\n",
      "Epoch 185/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1817\n",
      "\n",
      "Epoch 00185: loss did not improve from 0.17384\n",
      "Epoch 186/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1900\n",
      "\n",
      "Epoch 00186: loss did not improve from 0.17384\n",
      "Epoch 187/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.3010\n",
      "\n",
      "Epoch 00187: loss did not improve from 0.17384\n",
      "Epoch 188/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1318\n",
      "\n",
      "Epoch 00188: loss improved from 0.17384 to 0.13178, saving model to result/mse_weights/weights188-0.1318.h5\n",
      "Epoch 189/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1524\n",
      "\n",
      "Epoch 00189: loss did not improve from 0.13178\n",
      "Epoch 190/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1737\n",
      "\n",
      "Epoch 00190: loss did not improve from 0.13178\n",
      "Epoch 191/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2026\n",
      "\n",
      "Epoch 00191: loss did not improve from 0.13178\n",
      "Epoch 192/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1795\n",
      "\n",
      "Epoch 00192: loss did not improve from 0.13178\n",
      "Epoch 193/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1782\n",
      "\n",
      "Epoch 00193: loss did not improve from 0.13178\n",
      "Epoch 194/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1837\n",
      "\n",
      "Epoch 00194: loss did not improve from 0.13178\n",
      "Epoch 195/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.2614\n",
      "\n",
      "Epoch 00195: loss did not improve from 0.13178\n",
      "Epoch 196/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1957\n",
      "\n",
      "Epoch 00196: loss did not improve from 0.13178\n",
      "Epoch 197/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.3094\n",
      "\n",
      "Epoch 00197: loss did not improve from 0.13178\n",
      "Epoch 198/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.3128\n",
      "\n",
      "Epoch 00198: loss did not improve from 0.13178\n",
      "Epoch 199/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1345\n",
      "\n",
      "Epoch 00199: loss did not improve from 0.13178\n",
      "Epoch 200/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1467\n",
      "\n",
      "Epoch 00200: loss did not improve from 0.13178\n",
      "Epoch 201/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1782\n",
      "\n",
      "Epoch 00201: loss did not improve from 0.13178\n",
      "Epoch 202/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1728\n",
      "\n",
      "Epoch 00202: loss did not improve from 0.13178\n",
      "Epoch 203/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1831\n",
      "\n",
      "Epoch 00203: loss did not improve from 0.13178\n",
      "Epoch 204/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1511\n",
      "\n",
      "Epoch 00204: loss did not improve from 0.13178\n",
      "Epoch 205/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1478\n",
      "\n",
      "Epoch 00205: loss did not improve from 0.13178\n",
      "Epoch 206/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1646\n",
      "\n",
      "Epoch 00206: loss did not improve from 0.13178\n",
      "Epoch 207/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1674\n",
      "\n",
      "Epoch 00207: loss did not improve from 0.13178\n",
      "Epoch 208/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1461\n",
      "\n",
      "Epoch 00208: loss did not improve from 0.13178\n",
      "Epoch 209/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1535\n",
      "\n",
      "Epoch 00209: loss did not improve from 0.13178\n",
      "Epoch 210/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1577\n",
      "\n",
      "Epoch 00210: loss did not improve from 0.13178\n",
      "Epoch 211/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1429\n",
      "\n",
      "Epoch 00211: loss did not improve from 0.13178\n",
      "Epoch 212/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1592\n",
      "\n",
      "Epoch 00212: loss did not improve from 0.13178\n",
      "Epoch 213/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1698\n",
      "\n",
      "Epoch 00213: loss did not improve from 0.13178\n",
      "Epoch 214/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1280\n",
      "\n",
      "Epoch 00214: loss improved from 0.13178 to 0.12796, saving model to result/mse_weights/weights214-0.1280.h5\n",
      "Epoch 215/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1544\n",
      "\n",
      "Epoch 00215: loss did not improve from 0.12796\n",
      "Epoch 216/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1445\n",
      "\n",
      "Epoch 00216: loss did not improve from 0.12796\n",
      "Epoch 217/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1339\n",
      "\n",
      "Epoch 00217: loss did not improve from 0.12796\n",
      "Epoch 218/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1855\n",
      "\n",
      "Epoch 00218: loss did not improve from 0.12796\n",
      "Epoch 219/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1305\n",
      "\n",
      "Epoch 00219: loss did not improve from 0.12796\n",
      "Epoch 220/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1372\n",
      "\n",
      "Epoch 00220: loss did not improve from 0.12796\n",
      "Epoch 221/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1468\n",
      "\n",
      "Epoch 00221: loss did not improve from 0.12796\n",
      "Epoch 222/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1496\n",
      "\n",
      "Epoch 00222: loss did not improve from 0.12796\n",
      "Epoch 223/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1719\n",
      "\n",
      "Epoch 00223: loss did not improve from 0.12796\n",
      "Epoch 224/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1409\n",
      "\n",
      "Epoch 00224: loss did not improve from 0.12796\n",
      "Epoch 225/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1302\n",
      "\n",
      "Epoch 00225: loss did not improve from 0.12796\n",
      "Epoch 226/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1498\n",
      "\n",
      "Epoch 00226: loss did not improve from 0.12796\n",
      "Epoch 227/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1430\n",
      "\n",
      "Epoch 00227: loss did not improve from 0.12796\n",
      "Epoch 228/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1283\n",
      "\n",
      "Epoch 00228: loss did not improve from 0.12796\n",
      "Epoch 229/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.4423\n",
      "\n",
      "Epoch 00229: loss did not improve from 0.12796\n",
      "Epoch 230/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.4199\n",
      "\n",
      "Epoch 00230: loss did not improve from 0.12796\n",
      "Epoch 231/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.4070\n",
      "\n",
      "Epoch 00231: loss did not improve from 0.12796\n",
      "Epoch 232/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2764\n",
      "\n",
      "Epoch 00232: loss did not improve from 0.12796\n",
      "Epoch 233/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1645\n",
      "\n",
      "Epoch 00233: loss did not improve from 0.12796\n",
      "Epoch 234/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1223\n",
      "\n",
      "Epoch 00234: loss improved from 0.12796 to 0.12227, saving model to result/mse_weights/weights234-0.1223.h5\n",
      "Epoch 235/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1349\n",
      "\n",
      "Epoch 00235: loss did not improve from 0.12227\n",
      "Epoch 236/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1532\n",
      "\n",
      "Epoch 00236: loss did not improve from 0.12227\n",
      "Epoch 237/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1290\n",
      "\n",
      "Epoch 00237: loss did not improve from 0.12227\n",
      "Epoch 238/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1556\n",
      "\n",
      "Epoch 00238: loss did not improve from 0.12227\n",
      "Epoch 239/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1738\n",
      "\n",
      "Epoch 00239: loss did not improve from 0.12227\n",
      "Epoch 240/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1137\n",
      "\n",
      "Epoch 00240: loss improved from 0.12227 to 0.11365, saving model to result/mse_weights/weights240-0.1137.h5\n",
      "Epoch 241/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1328\n",
      "\n",
      "Epoch 00241: loss did not improve from 0.11365\n",
      "Epoch 242/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1165\n",
      "\n",
      "Epoch 00242: loss did not improve from 0.11365\n",
      "Epoch 243/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1739\n",
      "\n",
      "Epoch 00243: loss did not improve from 0.11365\n",
      "Epoch 244/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1336\n",
      "\n",
      "Epoch 00244: loss did not improve from 0.11365\n",
      "Epoch 245/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1266\n",
      "\n",
      "Epoch 00245: loss did not improve from 0.11365\n",
      "Epoch 246/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1275\n",
      "\n",
      "Epoch 00246: loss did not improve from 0.11365\n",
      "Epoch 247/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1863\n",
      "\n",
      "Epoch 00247: loss did not improve from 0.11365\n",
      "Epoch 248/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1194\n",
      "\n",
      "Epoch 00248: loss did not improve from 0.11365\n",
      "Epoch 249/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1191\n",
      "\n",
      "Epoch 00249: loss did not improve from 0.11365\n",
      "Epoch 250/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1183\n",
      "\n",
      "Epoch 00250: loss did not improve from 0.11365\n",
      "Epoch 251/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1384\n",
      "\n",
      "Epoch 00251: loss did not improve from 0.11365\n",
      "Epoch 252/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1300\n",
      "\n",
      "Epoch 00252: loss did not improve from 0.11365\n",
      "Epoch 253/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1135\n",
      "\n",
      "Epoch 00253: loss improved from 0.11365 to 0.11351, saving model to result/mse_weights/weights253-0.1135.h5\n",
      "Epoch 254/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1215\n",
      "\n",
      "Epoch 00254: loss did not improve from 0.11351\n",
      "Epoch 255/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1369\n",
      "\n",
      "Epoch 00255: loss did not improve from 0.11351\n",
      "Epoch 256/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1212\n",
      "\n",
      "Epoch 00256: loss did not improve from 0.11351\n",
      "Epoch 257/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1146\n",
      "\n",
      "Epoch 00257: loss did not improve from 0.11351\n",
      "Epoch 258/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1054\n",
      "\n",
      "Epoch 00258: loss improved from 0.11351 to 0.10543, saving model to result/mse_weights/weights258-0.1054.h5\n",
      "Epoch 259/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1226\n",
      "\n",
      "Epoch 00259: loss did not improve from 0.10543\n",
      "Epoch 260/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1118\n",
      "\n",
      "Epoch 00260: loss did not improve from 0.10543\n",
      "Epoch 261/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1303\n",
      "\n",
      "Epoch 00261: loss did not improve from 0.10543\n",
      "Epoch 262/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1038\n",
      "\n",
      "Epoch 00262: loss improved from 0.10543 to 0.10376, saving model to result/mse_weights/weights262-0.1038.h5\n",
      "Epoch 263/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1155\n",
      "\n",
      "Epoch 00263: loss did not improve from 0.10376\n",
      "Epoch 264/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1121\n",
      "\n",
      "Epoch 00264: loss did not improve from 0.10376\n",
      "Epoch 265/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1203\n",
      "\n",
      "Epoch 00265: loss did not improve from 0.10376\n",
      "Epoch 266/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1136\n",
      "\n",
      "Epoch 00266: loss did not improve from 0.10376\n",
      "Epoch 267/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1141\n",
      "\n",
      "Epoch 00267: loss did not improve from 0.10376\n",
      "Epoch 268/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1383\n",
      "\n",
      "Epoch 00268: loss did not improve from 0.10376\n",
      "Epoch 269/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1070\n",
      "\n",
      "Epoch 00269: loss did not improve from 0.10376\n",
      "Epoch 270/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1126\n",
      "\n",
      "Epoch 00270: loss did not improve from 0.10376\n",
      "Epoch 271/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1282\n",
      "\n",
      "Epoch 00271: loss did not improve from 0.10376\n",
      "Epoch 272/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1054\n",
      "\n",
      "Epoch 00272: loss did not improve from 0.10376\n",
      "Epoch 273/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1146\n",
      "\n",
      "Epoch 00273: loss did not improve from 0.10376\n",
      "Epoch 274/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1009\n",
      "\n",
      "Epoch 00274: loss improved from 0.10376 to 0.10089, saving model to result/mse_weights/weights274-0.1009.h5\n",
      "Epoch 275/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1052\n",
      "\n",
      "Epoch 00275: loss did not improve from 0.10089\n",
      "Epoch 276/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1069\n",
      "\n",
      "Epoch 00276: loss did not improve from 0.10089\n",
      "Epoch 277/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1041\n",
      "\n",
      "Epoch 00277: loss did not improve from 0.10089\n",
      "Epoch 278/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1170\n",
      "\n",
      "Epoch 00278: loss did not improve from 0.10089\n",
      "Epoch 279/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1018\n",
      "\n",
      "Epoch 00279: loss did not improve from 0.10089\n",
      "Epoch 280/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1128\n",
      "\n",
      "Epoch 00280: loss did not improve from 0.10089\n",
      "Epoch 281/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1492\n",
      "\n",
      "Epoch 00281: loss did not improve from 0.10089\n",
      "Epoch 282/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1002\n",
      "\n",
      "Epoch 00282: loss improved from 0.10089 to 0.10016, saving model to result/mse_weights/weights282-0.1002.h5\n",
      "Epoch 283/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1066\n",
      "\n",
      "Epoch 00283: loss did not improve from 0.10016\n",
      "Epoch 284/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0945\n",
      "\n",
      "Epoch 00284: loss improved from 0.10016 to 0.09450, saving model to result/mse_weights/weights284-0.0945.h5\n",
      "Epoch 285/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0995\n",
      "\n",
      "Epoch 00285: loss did not improve from 0.09450\n",
      "Epoch 286/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1012\n",
      "\n",
      "Epoch 00286: loss did not improve from 0.09450\n",
      "Epoch 287/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1086\n",
      "\n",
      "Epoch 00287: loss did not improve from 0.09450\n",
      "Epoch 288/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1001\n",
      "\n",
      "Epoch 00288: loss did not improve from 0.09450\n",
      "Epoch 289/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1050\n",
      "\n",
      "Epoch 00289: loss did not improve from 0.09450\n",
      "Epoch 290/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1056\n",
      "\n",
      "Epoch 00290: loss did not improve from 0.09450\n",
      "Epoch 291/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0902\n",
      "\n",
      "Epoch 00291: loss improved from 0.09450 to 0.09022, saving model to result/mse_weights/weights291-0.0902.h5\n",
      "Epoch 292/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1125\n",
      "\n",
      "Epoch 00292: loss did not improve from 0.09022\n",
      "Epoch 293/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0975\n",
      "\n",
      "Epoch 00293: loss did not improve from 0.09022\n",
      "Epoch 294/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0952\n",
      "\n",
      "Epoch 00294: loss did not improve from 0.09022\n",
      "Epoch 295/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0982\n",
      "\n",
      "Epoch 00295: loss did not improve from 0.09022\n",
      "Epoch 296/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1095\n",
      "\n",
      "Epoch 00296: loss did not improve from 0.09022\n",
      "Epoch 297/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0921\n",
      "\n",
      "Epoch 00297: loss did not improve from 0.09022\n",
      "Epoch 298/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0974\n",
      "\n",
      "Epoch 00298: loss did not improve from 0.09022\n",
      "Epoch 299/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1814\n",
      "\n",
      "Epoch 00299: loss did not improve from 0.09022\n",
      "Epoch 300/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1143\n",
      "\n",
      "Epoch 00300: loss did not improve from 0.09022\n",
      "Epoch 301/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0837\n",
      "\n",
      "Epoch 00301: loss improved from 0.09022 to 0.08368, saving model to result/mse_weights/weights301-0.0837.h5\n",
      "Epoch 302/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0881\n",
      "\n",
      "Epoch 00302: loss did not improve from 0.08368\n",
      "Epoch 303/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1036\n",
      "\n",
      "Epoch 00303: loss did not improve from 0.08368\n",
      "Epoch 304/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0885\n",
      "\n",
      "Epoch 00304: loss did not improve from 0.08368\n",
      "Epoch 305/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1017\n",
      "\n",
      "Epoch 00305: loss did not improve from 0.08368\n",
      "Epoch 306/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0911\n",
      "\n",
      "Epoch 00306: loss did not improve from 0.08368\n",
      "Epoch 307/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0957\n",
      "\n",
      "Epoch 00307: loss did not improve from 0.08368\n",
      "Epoch 308/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0978\n",
      "\n",
      "Epoch 00308: loss did not improve from 0.08368\n",
      "Epoch 309/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0902\n",
      "\n",
      "Epoch 00309: loss did not improve from 0.08368\n",
      "Epoch 310/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1068\n",
      "\n",
      "Epoch 00310: loss did not improve from 0.08368\n",
      "Epoch 311/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0896\n",
      "\n",
      "Epoch 00311: loss did not improve from 0.08368\n",
      "Epoch 312/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0948\n",
      "\n",
      "Epoch 00312: loss did not improve from 0.08368\n",
      "Epoch 313/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1054\n",
      "\n",
      "Epoch 00313: loss did not improve from 0.08368\n",
      "Epoch 314/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0939\n",
      "\n",
      "Epoch 00314: loss did not improve from 0.08368\n",
      "Epoch 315/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0959\n",
      "\n",
      "Epoch 00315: loss did not improve from 0.08368\n",
      "Epoch 316/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0952\n",
      "\n",
      "Epoch 00316: loss did not improve from 0.08368\n",
      "Epoch 317/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1316\n",
      "\n",
      "Epoch 00317: loss did not improve from 0.08368\n",
      "Epoch 318/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1003\n",
      "\n",
      "Epoch 00318: loss did not improve from 0.08368\n",
      "Epoch 319/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0828\n",
      "\n",
      "Epoch 00319: loss improved from 0.08368 to 0.08278, saving model to result/mse_weights/weights319-0.0828.h5\n",
      "Epoch 320/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1033\n",
      "\n",
      "Epoch 00320: loss did not improve from 0.08278\n",
      "Epoch 321/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0876\n",
      "\n",
      "Epoch 00321: loss did not improve from 0.08278\n",
      "Epoch 322/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0915\n",
      "\n",
      "Epoch 00322: loss did not improve from 0.08278\n",
      "Epoch 323/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0873\n",
      "\n",
      "Epoch 00323: loss did not improve from 0.08278\n",
      "Epoch 324/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0954\n",
      "\n",
      "Epoch 00324: loss did not improve from 0.08278\n",
      "Epoch 325/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1003\n",
      "\n",
      "Epoch 00325: loss did not improve from 0.08278\n",
      "Epoch 326/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0892\n",
      "\n",
      "Epoch 00326: loss did not improve from 0.08278\n",
      "Epoch 327/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0908\n",
      "\n",
      "Epoch 00327: loss did not improve from 0.08278\n",
      "Epoch 328/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0970\n",
      "\n",
      "Epoch 00328: loss did not improve from 0.08278\n",
      "Epoch 329/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0900\n",
      "\n",
      "Epoch 00329: loss did not improve from 0.08278\n",
      "Epoch 330/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0845\n",
      "\n",
      "Epoch 00330: loss did not improve from 0.08278\n",
      "Epoch 331/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1038\n",
      "\n",
      "Epoch 00331: loss did not improve from 0.08278\n",
      "Epoch 332/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0827\n",
      "\n",
      "Epoch 00332: loss improved from 0.08278 to 0.08268, saving model to result/mse_weights/weights332-0.0827.h5\n",
      "Epoch 333/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0863\n",
      "\n",
      "Epoch 00333: loss did not improve from 0.08268\n",
      "Epoch 334/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0878\n",
      "\n",
      "Epoch 00334: loss did not improve from 0.08268\n",
      "Epoch 335/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0937\n",
      "\n",
      "Epoch 00335: loss did not improve from 0.08268\n",
      "Epoch 336/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1115\n",
      "\n",
      "Epoch 00336: loss did not improve from 0.08268\n",
      "Epoch 337/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1343\n",
      "\n",
      "Epoch 00337: loss did not improve from 0.08268\n",
      "Epoch 338/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.2726\n",
      "\n",
      "Epoch 00338: loss did not improve from 0.08268\n",
      "Epoch 339/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1347\n",
      "\n",
      "Epoch 00339: loss did not improve from 0.08268\n",
      "Epoch 340/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0892\n",
      "\n",
      "Epoch 00340: loss did not improve from 0.08268\n",
      "Epoch 341/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0763\n",
      "\n",
      "Epoch 00341: loss improved from 0.08268 to 0.07627, saving model to result/mse_weights/weights341-0.0763.h5\n",
      "Epoch 342/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1115\n",
      "\n",
      "Epoch 00342: loss did not improve from 0.07627\n",
      "Epoch 343/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1052\n",
      "\n",
      "Epoch 00343: loss did not improve from 0.07627\n",
      "Epoch 344/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0751\n",
      "\n",
      "Epoch 00344: loss improved from 0.07627 to 0.07506, saving model to result/mse_weights/weights344-0.0751.h5\n",
      "Epoch 345/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0898\n",
      "\n",
      "Epoch 00345: loss did not improve from 0.07506\n",
      "Epoch 346/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0894\n",
      "\n",
      "Epoch 00346: loss did not improve from 0.07506\n",
      "Epoch 347/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1024\n",
      "\n",
      "Epoch 00347: loss did not improve from 0.07506\n",
      "Epoch 348/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0959\n",
      "\n",
      "Epoch 00348: loss did not improve from 0.07506\n",
      "Epoch 349/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0781\n",
      "\n",
      "Epoch 00349: loss did not improve from 0.07506\n",
      "Epoch 350/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0817\n",
      "\n",
      "Epoch 00350: loss did not improve from 0.07506\n",
      "Epoch 351/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1092\n",
      "\n",
      "Epoch 00351: loss did not improve from 0.07506\n",
      "Epoch 352/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0802\n",
      "\n",
      "Epoch 00352: loss did not improve from 0.07506\n",
      "Epoch 353/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0836\n",
      "\n",
      "Epoch 00353: loss did not improve from 0.07506\n",
      "Epoch 354/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0898\n",
      "\n",
      "Epoch 00354: loss did not improve from 0.07506\n",
      "Epoch 355/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1616\n",
      "\n",
      "Epoch 00355: loss did not improve from 0.07506\n",
      "Epoch 356/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0697\n",
      "\n",
      "Epoch 00356: loss improved from 0.07506 to 0.06971, saving model to result/mse_weights/weights356-0.0697.h5\n",
      "Epoch 357/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0714\n",
      "\n",
      "Epoch 00357: loss did not improve from 0.06971\n",
      "Epoch 358/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0906\n",
      "\n",
      "Epoch 00358: loss did not improve from 0.06971\n",
      "Epoch 359/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0896\n",
      "\n",
      "Epoch 00359: loss did not improve from 0.06971\n",
      "Epoch 360/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0795\n",
      "\n",
      "Epoch 00360: loss did not improve from 0.06971\n",
      "Epoch 361/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0842\n",
      "\n",
      "Epoch 00361: loss did not improve from 0.06971\n",
      "Epoch 362/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0798\n",
      "\n",
      "Epoch 00362: loss did not improve from 0.06971\n",
      "Epoch 363/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0833\n",
      "\n",
      "Epoch 00363: loss did not improve from 0.06971\n",
      "Epoch 364/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0879\n",
      "\n",
      "Epoch 00364: loss did not improve from 0.06971\n",
      "Epoch 365/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0874\n",
      "\n",
      "Epoch 00365: loss did not improve from 0.06971\n",
      "Epoch 366/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0757\n",
      "\n",
      "Epoch 00366: loss did not improve from 0.06971\n",
      "Epoch 367/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0852\n",
      "\n",
      "Epoch 00367: loss did not improve from 0.06971\n",
      "Epoch 368/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0812\n",
      "\n",
      "Epoch 00368: loss did not improve from 0.06971\n",
      "Epoch 369/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0802\n",
      "\n",
      "Epoch 00369: loss did not improve from 0.06971\n",
      "Epoch 370/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0882\n",
      "\n",
      "Epoch 00370: loss did not improve from 0.06971\n",
      "Epoch 371/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0801\n",
      "\n",
      "Epoch 00371: loss did not improve from 0.06971\n",
      "Epoch 372/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1218\n",
      "\n",
      "Epoch 00372: loss did not improve from 0.06971\n",
      "Epoch 373/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1466\n",
      "\n",
      "Epoch 00373: loss did not improve from 0.06971\n",
      "Epoch 374/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0670\n",
      "\n",
      "Epoch 00374: loss improved from 0.06971 to 0.06702, saving model to result/mse_weights/weights374-0.0670.h5\n",
      "Epoch 375/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0687\n",
      "\n",
      "Epoch 00375: loss did not improve from 0.06702\n",
      "Epoch 376/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0794\n",
      "\n",
      "Epoch 00376: loss did not improve from 0.06702\n",
      "Epoch 377/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1248\n",
      "\n",
      "Epoch 00377: loss did not improve from 0.06702\n",
      "Epoch 378/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0677\n",
      "\n",
      "Epoch 00378: loss did not improve from 0.06702\n",
      "Epoch 379/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0896\n",
      "\n",
      "Epoch 00379: loss did not improve from 0.06702\n",
      "Epoch 380/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0784\n",
      "\n",
      "Epoch 00380: loss did not improve from 0.06702\n",
      "Epoch 381/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0712\n",
      "\n",
      "Epoch 00381: loss did not improve from 0.06702\n",
      "Epoch 382/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0843\n",
      "\n",
      "Epoch 00382: loss did not improve from 0.06702\n",
      "Epoch 383/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0817\n",
      "\n",
      "Epoch 00383: loss did not improve from 0.06702\n",
      "Epoch 384/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0765\n",
      "\n",
      "Epoch 00384: loss did not improve from 0.06702\n",
      "Epoch 385/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1705\n",
      "\n",
      "Epoch 00385: loss did not improve from 0.06702\n",
      "Epoch 386/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1797\n",
      "\n",
      "Epoch 00386: loss did not improve from 0.06702\n",
      "Epoch 387/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1146\n",
      "\n",
      "Epoch 00387: loss did not improve from 0.06702\n",
      "Epoch 388/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0696\n",
      "\n",
      "Epoch 00388: loss did not improve from 0.06702\n",
      "Epoch 389/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0651\n",
      "\n",
      "Epoch 00389: loss improved from 0.06702 to 0.06509, saving model to result/mse_weights/weights389-0.0651.h5\n",
      "Epoch 390/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0718\n",
      "\n",
      "Epoch 00390: loss did not improve from 0.06509\n",
      "Epoch 391/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0833\n",
      "\n",
      "Epoch 00391: loss did not improve from 0.06509\n",
      "Epoch 392/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1075\n",
      "\n",
      "Epoch 00392: loss did not improve from 0.06509\n",
      "Epoch 393/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0687\n",
      "\n",
      "Epoch 00393: loss did not improve from 0.06509\n",
      "Epoch 394/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0771\n",
      "\n",
      "Epoch 00394: loss did not improve from 0.06509\n",
      "Epoch 395/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0750\n",
      "\n",
      "Epoch 00395: loss did not improve from 0.06509\n",
      "Epoch 396/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0813\n",
      "\n",
      "Epoch 00396: loss did not improve from 0.06509\n",
      "Epoch 397/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0892\n",
      "\n",
      "Epoch 00397: loss did not improve from 0.06509\n",
      "Epoch 398/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0727\n",
      "\n",
      "Epoch 00398: loss did not improve from 0.06509\n",
      "Epoch 399/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0832\n",
      "\n",
      "Epoch 00399: loss did not improve from 0.06509\n",
      "Epoch 400/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0707\n",
      "\n",
      "Epoch 00400: loss did not improve from 0.06509\n",
      "Epoch 401/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1159\n",
      "\n",
      "Epoch 00401: loss did not improve from 0.06509\n",
      "Epoch 402/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0658\n",
      "\n",
      "Epoch 00402: loss did not improve from 0.06509\n",
      "Epoch 403/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0774\n",
      "\n",
      "Epoch 00403: loss did not improve from 0.06509\n",
      "Epoch 404/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0693\n",
      "\n",
      "Epoch 00404: loss did not improve from 0.06509\n",
      "Epoch 405/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0853\n",
      "\n",
      "Epoch 00405: loss did not improve from 0.06509\n",
      "Epoch 406/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0686\n",
      "\n",
      "Epoch 00406: loss did not improve from 0.06509\n",
      "Epoch 407/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0820\n",
      "\n",
      "Epoch 00407: loss did not improve from 0.06509\n",
      "Epoch 408/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0667\n",
      "\n",
      "Epoch 00408: loss did not improve from 0.06509\n",
      "Epoch 409/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0853\n",
      "\n",
      "Epoch 00409: loss did not improve from 0.06509\n",
      "Epoch 410/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0785\n",
      "\n",
      "Epoch 00410: loss did not improve from 0.06509\n",
      "Epoch 411/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0718\n",
      "\n",
      "Epoch 00411: loss did not improve from 0.06509\n",
      "Epoch 412/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0705\n",
      "\n",
      "Epoch 00412: loss did not improve from 0.06509\n",
      "Epoch 413/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0842\n",
      "\n",
      "Epoch 00413: loss did not improve from 0.06509\n",
      "Epoch 414/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0706\n",
      "\n",
      "Epoch 00414: loss did not improve from 0.06509\n",
      "Epoch 415/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0814\n",
      "\n",
      "Epoch 00415: loss did not improve from 0.06509\n",
      "Epoch 416/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1203\n",
      "\n",
      "Epoch 00416: loss did not improve from 0.06509\n",
      "Epoch 417/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0623\n",
      "\n",
      "Epoch 00417: loss improved from 0.06509 to 0.06226, saving model to result/mse_weights/weights417-0.0623.h5\n",
      "Epoch 418/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0704\n",
      "\n",
      "Epoch 00418: loss did not improve from 0.06226\n",
      "Epoch 419/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0767\n",
      "\n",
      "Epoch 00419: loss did not improve from 0.06226\n",
      "Epoch 420/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0692\n",
      "\n",
      "Epoch 00420: loss did not improve from 0.06226\n",
      "Epoch 421/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0809\n",
      "\n",
      "Epoch 00421: loss did not improve from 0.06226\n",
      "Epoch 422/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0697\n",
      "\n",
      "Epoch 00422: loss did not improve from 0.06226\n",
      "Epoch 423/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0719\n",
      "\n",
      "Epoch 00423: loss did not improve from 0.06226\n",
      "Epoch 424/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0759\n",
      "\n",
      "Epoch 00424: loss did not improve from 0.06226\n",
      "Epoch 425/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0670\n",
      "\n",
      "Epoch 00425: loss did not improve from 0.06226\n",
      "Epoch 426/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0725\n",
      "\n",
      "Epoch 00426: loss did not improve from 0.06226\n",
      "Epoch 427/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0684\n",
      "\n",
      "Epoch 00427: loss did not improve from 0.06226\n",
      "Epoch 428/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0681\n",
      "\n",
      "Epoch 00428: loss did not improve from 0.06226\n",
      "Epoch 429/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0718\n",
      "\n",
      "Epoch 00429: loss did not improve from 0.06226\n",
      "Epoch 430/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0748\n",
      "\n",
      "Epoch 00430: loss did not improve from 0.06226\n",
      "Epoch 431/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0679\n",
      "\n",
      "Epoch 00431: loss did not improve from 0.06226\n",
      "Epoch 432/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0738\n",
      "\n",
      "Epoch 00432: loss did not improve from 0.06226\n",
      "Epoch 433/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0756\n",
      "\n",
      "Epoch 00433: loss did not improve from 0.06226\n",
      "Epoch 434/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0725\n",
      "\n",
      "Epoch 00434: loss did not improve from 0.06226\n",
      "Epoch 435/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0661\n",
      "\n",
      "Epoch 00435: loss did not improve from 0.06226\n",
      "Epoch 436/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0692\n",
      "\n",
      "Epoch 00436: loss did not improve from 0.06226\n",
      "Epoch 437/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0725\n",
      "\n",
      "Epoch 00437: loss did not improve from 0.06226\n",
      "Epoch 438/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0704\n",
      "\n",
      "Epoch 00438: loss did not improve from 0.06226\n",
      "Epoch 439/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0637\n",
      "\n",
      "Epoch 00439: loss did not improve from 0.06226\n",
      "Epoch 440/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1124\n",
      "\n",
      "Epoch 00440: loss did not improve from 0.06226\n",
      "Epoch 441/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1221\n",
      "\n",
      "Epoch 00441: loss did not improve from 0.06226\n",
      "Epoch 442/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0571\n",
      "\n",
      "Epoch 00442: loss improved from 0.06226 to 0.05706, saving model to result/mse_weights/weights442-0.0571.h5\n",
      "Epoch 443/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0688\n",
      "\n",
      "Epoch 00443: loss did not improve from 0.05706\n",
      "Epoch 444/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0691\n",
      "\n",
      "Epoch 00444: loss did not improve from 0.05706\n",
      "Epoch 445/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0672\n",
      "\n",
      "Epoch 00445: loss did not improve from 0.05706\n",
      "Epoch 446/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0666\n",
      "\n",
      "Epoch 00446: loss did not improve from 0.05706\n",
      "Epoch 447/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0696\n",
      "\n",
      "Epoch 00447: loss did not improve from 0.05706\n",
      "Epoch 448/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1379\n",
      "\n",
      "Epoch 00448: loss did not improve from 0.05706\n",
      "Epoch 449/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1175\n",
      "\n",
      "Epoch 00449: loss did not improve from 0.05706\n",
      "Epoch 450/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0613\n",
      "\n",
      "Epoch 00450: loss did not improve from 0.05706\n",
      "Epoch 451/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0718\n",
      "\n",
      "Epoch 00451: loss did not improve from 0.05706\n",
      "Epoch 452/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0668\n",
      "\n",
      "Epoch 00452: loss did not improve from 0.05706\n",
      "Epoch 453/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0770\n",
      "\n",
      "Epoch 00453: loss did not improve from 0.05706\n",
      "Epoch 454/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0606\n",
      "\n",
      "Epoch 00454: loss did not improve from 0.05706\n",
      "Epoch 455/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0715\n",
      "\n",
      "Epoch 00455: loss did not improve from 0.05706\n",
      "Epoch 456/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0690\n",
      "\n",
      "Epoch 00456: loss did not improve from 0.05706\n",
      "Epoch 457/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0764\n",
      "\n",
      "Epoch 00457: loss did not improve from 0.05706\n",
      "Epoch 458/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0628\n",
      "\n",
      "Epoch 00458: loss did not improve from 0.05706\n",
      "Epoch 459/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0778\n",
      "\n",
      "Epoch 00459: loss did not improve from 0.05706\n",
      "Epoch 460/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0639\n",
      "\n",
      "Epoch 00460: loss did not improve from 0.05706\n",
      "Epoch 461/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0675\n",
      "\n",
      "Epoch 00461: loss did not improve from 0.05706\n",
      "Epoch 462/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0661\n",
      "\n",
      "Epoch 00462: loss did not improve from 0.05706\n",
      "Epoch 463/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1040\n",
      "\n",
      "Epoch 00463: loss did not improve from 0.05706\n",
      "Epoch 464/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0495\n",
      "\n",
      "Epoch 00464: loss improved from 0.05706 to 0.04954, saving model to result/mse_weights/weights464-0.0495.h5\n",
      "Epoch 465/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0683\n",
      "\n",
      "Epoch 00465: loss did not improve from 0.04954\n",
      "Epoch 466/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0704\n",
      "\n",
      "Epoch 00466: loss did not improve from 0.04954\n",
      "Epoch 467/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0755\n",
      "\n",
      "Epoch 00467: loss did not improve from 0.04954\n",
      "Epoch 468/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0692\n",
      "\n",
      "Epoch 00468: loss did not improve from 0.04954\n",
      "Epoch 469/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0595\n",
      "\n",
      "Epoch 00469: loss did not improve from 0.04954\n",
      "Epoch 470/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0763\n",
      "\n",
      "Epoch 00470: loss did not improve from 0.04954\n",
      "Epoch 471/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0876\n",
      "\n",
      "Epoch 00471: loss did not improve from 0.04954\n",
      "Epoch 472/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1196\n",
      "\n",
      "Epoch 00472: loss did not improve from 0.04954\n",
      "Epoch 473/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0510\n",
      "\n",
      "Epoch 00473: loss did not improve from 0.04954\n",
      "Epoch 474/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1038\n",
      "\n",
      "Epoch 00474: loss did not improve from 0.04954\n",
      "Epoch 475/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0630\n",
      "\n",
      "Epoch 00475: loss did not improve from 0.04954\n",
      "Epoch 476/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0582\n",
      "\n",
      "Epoch 00476: loss did not improve from 0.04954\n",
      "Epoch 477/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0832\n",
      "\n",
      "Epoch 00477: loss did not improve from 0.04954\n",
      "Epoch 478/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1199\n",
      "\n",
      "Epoch 00478: loss did not improve from 0.04954\n",
      "Epoch 479/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0710\n",
      "\n",
      "Epoch 00479: loss did not improve from 0.04954\n",
      "Epoch 480/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0629\n",
      "\n",
      "Epoch 00480: loss did not improve from 0.04954\n",
      "Epoch 481/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0842\n",
      "\n",
      "Epoch 00481: loss did not improve from 0.04954\n",
      "Epoch 482/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0620\n",
      "\n",
      "Epoch 00482: loss did not improve from 0.04954\n",
      "Epoch 483/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0712\n",
      "\n",
      "Epoch 00483: loss did not improve from 0.04954\n",
      "Epoch 484/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0651\n",
      "\n",
      "Epoch 00484: loss did not improve from 0.04954\n",
      "Epoch 485/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0642\n",
      "\n",
      "Epoch 00485: loss did not improve from 0.04954\n",
      "Epoch 486/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0712\n",
      "\n",
      "Epoch 00486: loss did not improve from 0.04954\n",
      "Epoch 487/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0630\n",
      "\n",
      "Epoch 00487: loss did not improve from 0.04954\n",
      "Epoch 488/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0697\n",
      "\n",
      "Epoch 00488: loss did not improve from 0.04954\n",
      "Epoch 489/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0594\n",
      "\n",
      "Epoch 00489: loss did not improve from 0.04954\n",
      "Epoch 490/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0743\n",
      "\n",
      "Epoch 00490: loss did not improve from 0.04954\n",
      "Epoch 491/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0626\n",
      "\n",
      "Epoch 00491: loss did not improve from 0.04954\n",
      "Epoch 492/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.1761\n",
      "\n",
      "Epoch 00492: loss did not improve from 0.04954\n",
      "Epoch 493/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.1056\n",
      "\n",
      "Epoch 00493: loss did not improve from 0.04954\n",
      "Epoch 494/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0566\n",
      "\n",
      "Epoch 00494: loss did not improve from 0.04954\n",
      "Epoch 495/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0527\n",
      "\n",
      "Epoch 00495: loss did not improve from 0.04954\n",
      "Epoch 496/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0705\n",
      "\n",
      "Epoch 00496: loss did not improve from 0.04954\n",
      "Epoch 497/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0653\n",
      "\n",
      "Epoch 00497: loss did not improve from 0.04954\n",
      "Epoch 498/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0655\n",
      "\n",
      "Epoch 00498: loss did not improve from 0.04954\n",
      "Epoch 499/500\n",
      "2360/2360 [==============================] - 36s 15ms/step - loss: 0.0720\n",
      "\n",
      "Epoch 00499: loss did not improve from 0.04954\n",
      "Epoch 500/500\n",
      "2360/2360 [==============================] - 35s 15ms/step - loss: 0.0799\n",
      "\n",
      "Epoch 00500: loss did not improve from 0.04954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50448ed690>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_autoencoder.fit_generator(train_generator(x_train), epochs=epochs, steps_per_epoch=steps_per_epoch, verbose=1, callbacks=[early_stopping_callback, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = lstm_autoencoder.to_json()\n",
    "filename = 'last_mse_lstmae' # input('filename: ') #\n",
    "with open('model_save/mse_weights/' + filename + '.json', 'w') as file:\n",
    "    file.write(model_json)\n",
    "lstm_autoencoder.save_weights('model_save/mse_weights/weights_' +  filename + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1010 15:48:40.110543 140189195294464 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1010 15:48:40.120297 140189195294464 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1010 15:48:40.123097 140189195294464 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1010 15:48:40.688915 140189195294464 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1010 15:48:40.689456 140189195294464 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"last_mse_lstmae\"\n",
    "loaded_model = model_from_json(open('model_save/mse_weights/' +filename + '.json').read())\n",
    "loaded_model.load_weights('model_save/mse_weights/weights_' + filename + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm_autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e2fee70f2288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_autoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lstm_autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "loaded_model = lstm_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7717624475759962\n"
     ]
    }
   ],
   "source": [
    "mean= 0\n",
    "for xt in x_test:\n",
    "    xt = xt.reshape(1, xt.shape[0], xt.shape[1])\n",
    "    out = loaded_model.predict(xt)\n",
    "    mean += ((xt-out)**2).mean(axis=None)\n",
    "print(mean/len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(loaded_model.input, loaded_model.layers[3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = x_test[0].reshape(1, x_test[0].shape[0], x_test[0].shape[1])\n",
    "latent_vector = []\n",
    "for x in x_test:\n",
    "    x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "    latent_vector.append(encoder.predict(x)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
