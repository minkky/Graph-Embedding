{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob, os\n",
    "from keras import layers as ly\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Lambda\n",
    "from keras import losses\n",
    "from keras.models import model_from_json\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir = './sequence/*'\n",
    "dir = './datasets/latest_seq/bfs-character/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file read\n",
    "all_names = []\n",
    "all_data = []\n",
    "sequence_length = []\n",
    "alpha = list(string.ascii_uppercase)\n",
    "data_length = len(glob.glob(dir))\n",
    "file_predix = './datasets/latest_seq/bfs-character/graph'\n",
    "for index in range(data_length):\n",
    "    filename = file_predix + str(index) + \"-*\"\n",
    "    files = glob.glob(filename)\n",
    "    for file in files:\n",
    "        datasets = []\n",
    "        all_names.append(file.split('/')[-1].replace('.txt', ''))\n",
    "        for rf in open(file, 'r'):\n",
    "            (u, v, w) = rf[1:-2].split(', ')\n",
    "            datasets.append([alpha.index(u[1])+1, alpha.index(v[1]) +1, float(w)])\n",
    "        sequence_length.append(len(datasets))\n",
    "        all_data.append(datasets)\n",
    "all_data = np.array([np.array(arr) for arr in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, train_name, test_name = train_test_split(all_data, all_names, test_size=0.3)\n",
    "x_test, x_val, test_name, val_name = train_test_split(x_test, test_name, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name\n",
    "tr_names= []\n",
    "for name in train_name:\n",
    "    tr_names.append(name.split('-')[0].replace('graph', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max(sequence_length)\n",
    "n_features = 3\n",
    "batch_size = 32\n",
    "epochs = 500\n",
    "steps_per_epoch = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    loss1 = losses.mean_squared_error(y_true, y_pred)\n",
    "    #loss2 = losses.kld(y_true, y_pred)\n",
    "    return loss1# * 0.7 + loss2 * 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def repeat_vector(args):\n",
    "    layer_to_repeat = args[0]\n",
    "    sequence_layer = args[1]\n",
    "    return RepeatVector(K.shape(sequence_layer)[1])(layer_to_repeat)\n",
    "    \n",
    "\n",
    "inputs = Input(shape=(None, 3))\n",
    "encoded = LSTM(128, return_sequences=True)(inputs)  #activation 안적으면 tanh\n",
    "encoded = LSTM(64)(encoded)\n",
    "\n",
    "decoded = Lambda(repeat_vector, output_shape=(None, 64)) ([encoded, inputs]) # inputs의 shape[1] 만큼 encoded 를 반복 생성\n",
    "\n",
    "decoded = LSTM(64, return_sequences=True)(decoded)\n",
    "decoded = LSTM(128, return_sequences=True)(decoded)\n",
    "decoded = TimeDistributed(Dense(3))(decoded)\n",
    "encoder = Model(inputs, encoded)\n",
    "\n",
    "lstm_autoencoder = Model(inputs, decoded)\n",
    "lstm_autoencoder.compile(loss=custom_loss, optimizer=Adam())#lr=1e-2, decay=0.9))\n",
    "#lstm_autoencoder_500 = lstm_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_generator(x_val):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        yield np.array([x_val[idx]]), np.array([x_val[idx]])\n",
    "        idx += 1\n",
    "        if idx >= len(x_val):\n",
    "            idx = 0\n",
    "\n",
    "def train_generator(x_train):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        yield np.array([x_train[idx]]), np.array([x_train[idx]])\n",
    "        idx += 1\n",
    "        if idx >= len(x_train):\n",
    "            idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/300\n",
      "4914/4914 [==============================] - 45s 9ms/step - loss: 72.9445 - val_loss: 78.8365\n",
      "Epoch 2/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 72.3800 - val_loss: 78.8043\n",
      "Epoch 3/300\n",
      "4914/4914 [==============================] - 44s 9ms/step - loss: 72.3699 - val_loss: 78.7898\n",
      "Epoch 4/300\n",
      "4914/4914 [==============================] - 44s 9ms/step - loss: 68.1347 - val_loss: 29.2320\n",
      "Epoch 5/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 21.4132 - val_loss: 18.6795\n",
      "Epoch 6/300\n",
      "4914/4914 [==============================] - 44s 9ms/step - loss: 16.1285 - val_loss: 14.5128\n",
      "Epoch 7/300\n",
      "4914/4914 [==============================] - 44s 9ms/step - loss: 13.2504 - val_loss: 11.9474\n",
      "Epoch 8/300\n",
      "4914/4914 [==============================] - 44s 9ms/step - loss: 11.3367 - val_loss: 10.2744\n",
      "Epoch 9/300\n",
      "4914/4914 [==============================] - 44s 9ms/step - loss: 9.5876 - val_loss: 8.7352\n",
      "Epoch 10/300\n",
      "4914/4914 [==============================] - 44s 9ms/step - loss: 8.0545 - val_loss: 6.7283\n",
      "Epoch 11/300\n",
      "4914/4914 [==============================] - 44s 9ms/step - loss: 6.3961 - val_loss: 6.1002\n",
      "Epoch 12/300\n",
      "4914/4914 [==============================] - 44s 9ms/step - loss: 5.5703 - val_loss: 4.7785\n",
      "Epoch 13/300\n",
      "4914/4914 [==============================] - 44s 9ms/step - loss: 4.9633 - val_loss: 4.2120\n",
      "Epoch 14/300\n",
      "4914/4914 [==============================] - 44s 9ms/step - loss: 4.5607 - val_loss: 4.1043\n",
      "Epoch 15/300\n",
      "4914/4914 [==============================] - 44s 9ms/step - loss: 4.1174 - val_loss: 3.9803\n",
      "Epoch 16/300\n",
      "4914/4914 [==============================] - 45s 9ms/step - loss: 3.8175 - val_loss: 3.8286\n",
      "Epoch 17/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 3.3256 - val_loss: 3.2021\n",
      "Epoch 18/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 2.9068 - val_loss: 3.1477\n",
      "Epoch 19/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 2.5296 - val_loss: 2.8025\n",
      "Epoch 20/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 2.3150 - val_loss: 2.7096\n",
      "Epoch 21/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 2.1612 - val_loss: 2.4288\n",
      "Epoch 22/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 1.9656 - val_loss: 2.1805\n",
      "Epoch 23/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 1.8332 - val_loss: 1.8829\n",
      "Epoch 24/300\n",
      "4914/4914 [==============================] - 44s 9ms/step - loss: 1.7557 - val_loss: 1.7947\n",
      "Epoch 25/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 1.6118 - val_loss: 1.8871\n",
      "Epoch 26/300\n",
      "4914/4914 [==============================] - 44s 9ms/step - loss: 1.4983 - val_loss: 1.7318\n",
      "Epoch 27/300\n",
      "4914/4914 [==============================] - 44s 9ms/step - loss: 1.4118 - val_loss: 1.6635\n",
      "Epoch 28/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 1.3913 - val_loss: 1.5423\n",
      "Epoch 29/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 1.3724 - val_loss: 1.7497\n",
      "Epoch 30/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 1.1885 - val_loss: 1.3191\n",
      "Epoch 31/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 1.1464 - val_loss: 1.3514\n",
      "Epoch 32/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 1.0993 - val_loss: 1.3079\n",
      "Epoch 33/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 1.0896 - val_loss: 1.2669\n",
      "Epoch 34/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 1.0026 - val_loss: 1.3356\n",
      "Epoch 35/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.9662 - val_loss: 1.1833\n",
      "Epoch 36/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.9045 - val_loss: 1.1133\n",
      "Epoch 37/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.9686 - val_loss: 1.2020\n",
      "Epoch 38/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.8456 - val_loss: 1.2785\n",
      "Epoch 39/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.8686 - val_loss: 1.0831\n",
      "Epoch 40/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.9168 - val_loss: 1.0152\n",
      "Epoch 41/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.7639 - val_loss: 1.1429\n",
      "Epoch 42/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.7618 - val_loss: 1.1564\n",
      "Epoch 43/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.7315 - val_loss: 1.0042\n",
      "Epoch 44/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.7498 - val_loss: 1.0527\n",
      "Epoch 45/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.7148 - val_loss: 1.0597\n",
      "Epoch 46/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.6605 - val_loss: 1.0748\n",
      "Epoch 47/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.6946 - val_loss: 0.9516\n",
      "Epoch 48/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.6949 - val_loss: 0.9978\n",
      "Epoch 49/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.6213 - val_loss: 0.9268\n",
      "Epoch 50/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.6340 - val_loss: 0.9271\n",
      "Epoch 51/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.6107 - val_loss: 0.9006\n",
      "Epoch 52/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.6394 - val_loss: 0.8668\n",
      "Epoch 53/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.6159 - val_loss: 0.9178\n",
      "Epoch 54/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.5965 - val_loss: 0.8632\n",
      "Epoch 55/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.6245 - val_loss: 0.8514\n",
      "Epoch 56/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.5604 - val_loss: 0.8352\n",
      "Epoch 57/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.5416 - val_loss: 1.0426\n",
      "Epoch 58/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.5490 - val_loss: 0.8924\n",
      "Epoch 59/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.5385 - val_loss: 0.9319\n",
      "Epoch 60/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.5308 - val_loss: 0.9205\n",
      "Epoch 61/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.4971 - val_loss: 0.8224\n",
      "Epoch 62/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.4878 - val_loss: 0.8460\n",
      "Epoch 63/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.5376 - val_loss: 0.8190\n",
      "Epoch 64/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.4721 - val_loss: 0.8287\n",
      "Epoch 65/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.4938 - val_loss: 0.7937\n",
      "Epoch 66/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.4827 - val_loss: 0.8458\n",
      "Epoch 67/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.4687 - val_loss: 0.7393\n",
      "Epoch 68/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.4526 - val_loss: 0.8144\n",
      "Epoch 69/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.4674 - val_loss: 0.8021\n",
      "Epoch 70/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.4965 - val_loss: 0.6994\n",
      "Epoch 71/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.4277 - val_loss: 0.8538\n",
      "Epoch 72/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.4324 - val_loss: 0.8463\n",
      "Epoch 73/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.4539 - val_loss: 0.7806\n",
      "Epoch 74/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.4287 - val_loss: 0.8010\n",
      "Epoch 75/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.4623 - val_loss: 0.7692\n",
      "Epoch 76/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.5404 - val_loss: 1.1382\n",
      "Epoch 77/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3974 - val_loss: 0.8239\n",
      "Epoch 78/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.4439 - val_loss: 0.7975\n",
      "Epoch 79/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.4084 - val_loss: 0.8374\n",
      "Epoch 80/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3919 - val_loss: 0.8319\n",
      "Epoch 81/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.4321 - val_loss: 0.8134\n",
      "Epoch 82/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.4358 - val_loss: 0.7255\n",
      "Epoch 83/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3865 - val_loss: 0.7045\n",
      "Epoch 84/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3874 - val_loss: 0.7464\n",
      "Epoch 85/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3836 - val_loss: 0.7667\n",
      "Epoch 86/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.4037 - val_loss: 0.7479\n",
      "Epoch 87/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3825 - val_loss: 0.8236\n",
      "Epoch 88/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3748 - val_loss: 0.8469\n",
      "Epoch 89/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3672 - val_loss: 0.8206\n",
      "Epoch 90/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3721 - val_loss: 0.7669\n",
      "Epoch 91/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3505 - val_loss: 0.8091\n",
      "Epoch 92/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3789 - val_loss: 0.7590\n",
      "Epoch 93/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3600 - val_loss: 0.8036\n",
      "Epoch 94/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.4550 - val_loss: 0.6650\n",
      "Epoch 95/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3461 - val_loss: 0.7088\n",
      "Epoch 96/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3507 - val_loss: 0.6698\n",
      "Epoch 97/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3376 - val_loss: 0.6960\n",
      "Epoch 98/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3328 - val_loss: 0.6655\n",
      "Epoch 99/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3250 - val_loss: 0.7511\n",
      "Epoch 100/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3281 - val_loss: 0.7623\n",
      "Epoch 101/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3285 - val_loss: 0.6539\n",
      "Epoch 102/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3459 - val_loss: 0.7547\n",
      "Epoch 103/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3230 - val_loss: 0.6924\n",
      "Epoch 104/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3182 - val_loss: 0.7355\n",
      "Epoch 105/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3233 - val_loss: 0.6716\n",
      "Epoch 106/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3133 - val_loss: 0.7327\n",
      "Epoch 107/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3144 - val_loss: 0.6701\n",
      "Epoch 108/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3087 - val_loss: 0.6910\n",
      "Epoch 109/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3449 - val_loss: 0.7425\n",
      "Epoch 110/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3120 - val_loss: 0.7447\n",
      "Epoch 111/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3215 - val_loss: 0.8000\n",
      "Epoch 112/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3068 - val_loss: 0.7160\n",
      "Epoch 113/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2945 - val_loss: 0.7537\n",
      "Epoch 114/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3004 - val_loss: 0.7374\n",
      "Epoch 115/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3129 - val_loss: 0.7111\n",
      "Epoch 116/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3220 - val_loss: 0.6680\n",
      "Epoch 117/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2859 - val_loss: 0.7070\n",
      "Epoch 118/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2953 - val_loss: 0.7535\n",
      "Epoch 119/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2943 - val_loss: 0.7489\n",
      "Epoch 120/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2931 - val_loss: 0.6661\n",
      "Epoch 121/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2786 - val_loss: 0.7039\n",
      "Epoch 122/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2953 - val_loss: 0.7108\n",
      "Epoch 123/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3694 - val_loss: 1.0645\n",
      "Epoch 124/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3517 - val_loss: 0.6271\n",
      "Epoch 125/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2967 - val_loss: 0.7039\n",
      "Epoch 126/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3586 - val_loss: 0.6442\n",
      "Epoch 127/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3254 - val_loss: 0.9332\n",
      "Epoch 128/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2969 - val_loss: 0.8302\n",
      "Epoch 129/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3164 - val_loss: 0.6779\n",
      "Epoch 130/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3723 - val_loss: 1.0033\n",
      "Epoch 131/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3485 - val_loss: 0.6824\n",
      "Epoch 132/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3079 - val_loss: 0.6698\n",
      "Epoch 133/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2769 - val_loss: 0.6711\n",
      "Epoch 134/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2738 - val_loss: 0.6991\n",
      "Epoch 135/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3096 - val_loss: 1.1842\n",
      "Epoch 136/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3297 - val_loss: 0.7076\n",
      "Epoch 137/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2655 - val_loss: 0.6697\n",
      "Epoch 138/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.4807 - val_loss: 0.6823\n",
      "Epoch 139/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3002 - val_loss: 0.7492\n",
      "Epoch 140/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3204 - val_loss: 0.7528\n",
      "Epoch 141/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2725 - val_loss: 0.6833\n",
      "Epoch 142/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3098 - val_loss: 0.6635\n",
      "Epoch 143/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2764 - val_loss: 0.7002\n",
      "Epoch 144/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3006 - val_loss: 0.6693\n",
      "Epoch 145/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2532 - val_loss: 0.7599\n",
      "Epoch 146/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2628 - val_loss: 0.6395\n",
      "Epoch 147/300\n",
      "4914/4914 [==============================] - 42s 9ms/step - loss: 0.2523 - val_loss: 0.6673\n",
      "Epoch 148/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2967 - val_loss: 0.7034\n",
      "Epoch 149/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.2649 - val_loss: 0.6829\n",
      "Epoch 150/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.4165 - val_loss: 0.6718\n",
      "Epoch 151/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.7758 - val_loss: 0.9483\n",
      "Epoch 152/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.5305 - val_loss: 0.9045\n",
      "Epoch 153/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.4570 - val_loss: 1.4744\n",
      "Epoch 154/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.5634 - val_loss: 0.8433\n",
      "Epoch 155/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.3522 - val_loss: 0.7373\n",
      "Epoch 156/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2801 - val_loss: 0.6353\n",
      "Epoch 157/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3442 - val_loss: 0.8588\n",
      "Epoch 158/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3251 - val_loss: 0.7811\n",
      "Epoch 159/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3432 - val_loss: 0.7650\n",
      "Epoch 160/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3822 - val_loss: 1.1836\n",
      "Epoch 161/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3992 - val_loss: 0.6761\n",
      "Epoch 162/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3886 - val_loss: 0.6941\n",
      "Epoch 163/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2869 - val_loss: 0.6340\n",
      "Epoch 164/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3422 - val_loss: 0.8228\n",
      "Epoch 165/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.4950 - val_loss: 0.9689\n",
      "Epoch 166/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.5475 - val_loss: 0.9101\n",
      "Epoch 167/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.4762 - val_loss: 0.8979\n",
      "Epoch 168/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3534 - val_loss: 0.6978\n",
      "Epoch 169/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3390 - val_loss: 0.6697\n",
      "Epoch 170/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3753 - val_loss: 0.6597\n",
      "Epoch 171/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2743 - val_loss: 0.6902\n",
      "Epoch 172/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3855 - val_loss: 0.8930\n",
      "Epoch 173/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3283 - val_loss: 0.8865\n",
      "Epoch 174/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3628 - val_loss: 0.6368\n",
      "Epoch 175/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2737 - val_loss: 0.6809\n",
      "Epoch 176/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.3604 - val_loss: 0.9295\n",
      "Epoch 177/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2674 - val_loss: 0.7211\n",
      "Epoch 178/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2596 - val_loss: 0.6956\n",
      "Epoch 179/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2689 - val_loss: 0.7474\n",
      "Epoch 180/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2609 - val_loss: 0.7983\n",
      "Epoch 181/300\n",
      "4914/4914 [==============================] - 42s 9ms/step - loss: 0.2653 - val_loss: 0.6608\n",
      "Epoch 182/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2483 - val_loss: 0.6880\n",
      "Epoch 183/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2512 - val_loss: 0.7010\n",
      "Epoch 184/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.3274 - val_loss: 1.0399\n",
      "Epoch 185/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.3540 - val_loss: 0.6503\n",
      "Epoch 186/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2422 - val_loss: 0.6276\n",
      "Epoch 187/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2393 - val_loss: 0.6225\n",
      "Epoch 188/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.4244 - val_loss: 0.7171\n",
      "Epoch 189/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2768 - val_loss: 0.7190\n",
      "Epoch 190/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2981 - val_loss: 0.6690\n",
      "Epoch 191/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2642 - val_loss: 0.6005\n",
      "Epoch 192/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2702 - val_loss: 0.5855\n",
      "Epoch 193/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2419 - val_loss: 0.6326\n",
      "Epoch 194/300\n",
      "4914/4914 [==============================] - 42s 9ms/step - loss: 0.2418 - val_loss: 0.7512\n",
      "Epoch 195/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2378 - val_loss: 0.7549\n",
      "Epoch 196/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.3488 - val_loss: 0.6633\n",
      "Epoch 197/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2729 - val_loss: 0.6684\n",
      "Epoch 198/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2329 - val_loss: 0.6205\n",
      "Epoch 199/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2423 - val_loss: 0.9435\n",
      "Epoch 200/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.4578 - val_loss: 0.7053\n",
      "Epoch 201/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2412 - val_loss: 0.6675\n",
      "Epoch 202/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2896 - val_loss: 0.6344\n",
      "Epoch 203/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2215 - val_loss: 0.6869\n",
      "Epoch 204/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2324 - val_loss: 0.6162\n",
      "Epoch 205/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2284 - val_loss: 0.6324\n",
      "Epoch 206/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2767 - val_loss: 0.6634\n",
      "Epoch 207/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2572 - val_loss: 0.6965\n",
      "Epoch 208/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2380 - val_loss: 0.6099\n",
      "Epoch 209/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2265 - val_loss: 0.6579\n",
      "Epoch 210/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2292 - val_loss: 0.7688\n",
      "Epoch 211/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2369 - val_loss: 0.6502\n",
      "Epoch 212/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2523 - val_loss: 0.6569\n",
      "Epoch 213/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2773 - val_loss: 0.6445\n",
      "Epoch 214/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2143 - val_loss: 0.6730\n",
      "Epoch 215/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2793 - val_loss: 0.6761\n",
      "Epoch 216/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2269 - val_loss: 0.7952\n",
      "Epoch 217/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2334 - val_loss: 0.6542\n",
      "Epoch 218/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2021 - val_loss: 0.7101\n",
      "Epoch 219/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2121 - val_loss: 0.6914\n",
      "Epoch 220/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2469 - val_loss: 0.6113\n",
      "Epoch 221/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2071 - val_loss: 0.7339\n",
      "Epoch 222/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2047 - val_loss: 0.6662\n",
      "Epoch 223/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2056 - val_loss: 0.6566\n",
      "Epoch 224/300\n",
      "4914/4914 [==============================] - 42s 8ms/step - loss: 0.2238 - val_loss: 0.9688\n",
      "Epoch 225/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2037 - val_loss: 0.6618\n",
      "Epoch 226/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2107 - val_loss: 0.6832\n",
      "Epoch 227/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.2211 - val_loss: 0.7310\n",
      "Epoch 228/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.2282 - val_loss: 0.7656\n",
      "Epoch 229/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1960 - val_loss: 0.6531\n",
      "Epoch 230/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1940 - val_loss: 0.6267\n",
      "Epoch 231/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2103 - val_loss: 0.6728\n",
      "Epoch 232/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2213 - val_loss: 0.8166\n",
      "Epoch 233/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1929 - val_loss: 0.7051\n",
      "Epoch 234/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1914 - val_loss: 0.6803\n",
      "Epoch 235/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1922 - val_loss: 0.6968\n",
      "Epoch 236/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1947 - val_loss: 0.6836\n",
      "Epoch 237/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1972 - val_loss: 0.6570\n",
      "Epoch 238/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2106 - val_loss: 0.6481\n",
      "Epoch 239/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.1873 - val_loss: 0.6645\n",
      "Epoch 240/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2020 - val_loss: 0.8448\n",
      "Epoch 241/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1926 - val_loss: 0.6814\n",
      "Epoch 242/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1923 - val_loss: 0.6830\n",
      "Epoch 243/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1875 - val_loss: 0.6812\n",
      "Epoch 244/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1897 - val_loss: 0.6541\n",
      "Epoch 245/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2051 - val_loss: 0.6194\n",
      "Epoch 246/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1842 - val_loss: 0.6903\n",
      "Epoch 247/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1877 - val_loss: 0.6419\n",
      "Epoch 248/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1927 - val_loss: 0.6337\n",
      "Epoch 249/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1840 - val_loss: 0.6690\n",
      "Epoch 250/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1820 - val_loss: 0.6437\n",
      "Epoch 251/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1830 - val_loss: 0.6831\n",
      "Epoch 252/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1851 - val_loss: 0.6454\n",
      "Epoch 253/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1707 - val_loss: 0.6725\n",
      "Epoch 254/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1827 - val_loss: 0.6835\n",
      "Epoch 255/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1924 - val_loss: 0.6480\n",
      "Epoch 256/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1884 - val_loss: 0.6632\n",
      "Epoch 257/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 0.1793 - val_loss: 0.6579\n",
      "Epoch 258/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1788 - val_loss: 0.6432\n",
      "Epoch 259/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1740 - val_loss: 0.6654\n",
      "Epoch 260/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1838 - val_loss: 0.6843\n",
      "Epoch 261/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2029 - val_loss: 0.6561\n",
      "Epoch 262/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1723 - val_loss: 0.6572\n",
      "Epoch 263/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1869 - val_loss: 0.6071\n",
      "Epoch 264/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1704 - val_loss: 0.6847\n",
      "Epoch 265/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1808 - val_loss: 0.7099\n",
      "Epoch 266/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1688 - val_loss: 0.6215\n",
      "Epoch 267/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1814 - val_loss: 0.6521\n",
      "Epoch 268/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1845 - val_loss: 0.8502\n",
      "Epoch 269/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1715 - val_loss: 0.7251\n",
      "Epoch 270/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1788 - val_loss: 0.6502\n",
      "Epoch 271/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1681 - val_loss: 0.7030\n",
      "Epoch 272/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1772 - val_loss: 0.6825\n",
      "Epoch 273/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1686 - val_loss: 0.6780\n",
      "Epoch 274/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1723 - val_loss: 0.7512\n",
      "Epoch 275/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1708 - val_loss: 0.6437\n",
      "Epoch 276/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1637 - val_loss: 0.7169\n",
      "Epoch 277/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1767 - val_loss: 0.6668\n",
      "Epoch 278/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1709 - val_loss: 0.6107\n",
      "Epoch 279/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1969 - val_loss: 0.6576\n",
      "Epoch 280/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1636 - val_loss: 0.6162\n",
      "Epoch 281/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1671 - val_loss: 0.6685\n",
      "Epoch 282/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1669 - val_loss: 0.6609\n",
      "Epoch 283/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1679 - val_loss: 0.6456\n",
      "Epoch 284/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1715 - val_loss: 0.7216\n",
      "Epoch 285/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.2201 - val_loss: 0.7808\n",
      "Epoch 286/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1717 - val_loss: 0.6981\n",
      "Epoch 287/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1701 - val_loss: 0.6847\n",
      "Epoch 288/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1681 - val_loss: 0.6607\n",
      "Epoch 289/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1646 - val_loss: 0.6526\n",
      "Epoch 290/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1687 - val_loss: 0.7026\n",
      "Epoch 291/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1632 - val_loss: 0.6495\n",
      "Epoch 292/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1695 - val_loss: 0.6620\n",
      "Epoch 293/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1628 - val_loss: 0.6504\n",
      "Epoch 294/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1700 - val_loss: 0.6543\n",
      "Epoch 295/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1556 - val_loss: 0.6530\n",
      "Epoch 296/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1603 - val_loss: 0.7212\n",
      "Epoch 297/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1584 - val_loss: 0.6577\n",
      "Epoch 298/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1592 - val_loss: 0.7052\n",
      "Epoch 299/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1634 - val_loss: 0.6545\n",
      "Epoch 300/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 0.1755 - val_loss: 0.7297\n"
     ]
    }
   ],
   "source": [
    "hist = lstm_autoencoder.fit_generator(train_generator(x_train), epochs=300, steps_per_epoch=steps_per_epoch, verbose=1, validation_steps=len(x_val), validation_data=val_generator(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = lstm_autoencoder.to_json()\n",
    "filename = 'new_mse_lstmae' # input('filename: ') #\n",
    "with open('model_save/mse_weights/' + filename + '.json', 'w') as file:\n",
    "    file.write(model_json)\n",
    "lstm_autoencoder.save_weights('model_save/mse_weights/weights_' +  filename + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('model_save/mse_weights/new_mse_history.json', 'w') as f:\n",
    "    json.dump(hist.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "loss_ax.plot(hist.history['val_loss'], 'b', label='val loss')\n",
    "loss_ax.plot(hist.history['loss'], 'r', label='train loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.title('mse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1010 15:48:40.110543 140189195294464 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1010 15:48:40.120297 140189195294464 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1010 15:48:40.123097 140189195294464 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1010 15:48:40.688915 140189195294464 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W1010 15:48:40.689456 140189195294464 deprecation_wrapper.py:119] From /home/minji/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"last_mse_lstmae\"\n",
    "loaded_model = model_from_json(open('model_save/mse_weights/' +filename + '.json').read())\n",
    "loaded_model.load_weights('model_save/mse_weights/weights_' + filename + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = lstm_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6394187008665996\n"
     ]
    }
   ],
   "source": [
    "mean= 0\n",
    "for xt in x_test:\n",
    "    xt = xt.reshape(1, xt.shape[0], xt.shape[1])\n",
    "    out = loaded_model.predict(xt)\n",
    "    mean += ((xt-out)**2).mean(axis=None)\n",
    "print(mean/len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(loaded_model.input, loaded_model.layers[3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = x_test[0].reshape(1, x_test[0].shape[0], x_test[0].shape[1])\n",
    "latent_vector = []\n",
    "for x in x_test:\n",
    "    x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "    latent_vector.append(encoder.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_save/mse_weights/weights' + '{epoch:02d}-{loss:.4f}.h5'\n",
    "early_stopping_callback = EarlyStopping(monitor='loss', patience=200)\n",
    "checkpoint_callback = ModelCheckpoint(model_path, monitor='loss', verbose = 1, save_best_only = True, save_weights_only = True, mode='min')#, period=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def train_generator(x_train):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        leng = len(x_train[idx])\n",
    "        dt = [x_train[idx]]\n",
    "        while(leng == len(x_train[idx+1]) and idx < len(x_train)):\n",
    "            dt += [x_train[idx+1]]\n",
    "            idx += 1\n",
    "            if len(dt) >= 100:\n",
    "                break\n",
    "        yield np.array(dt), np.array(dt)\n",
    "        if idx >= len(x_train):\n",
    "            break\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
