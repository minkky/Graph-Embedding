{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob, os\n",
    "from keras import layers as ly\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir = './sequence/*'\n",
    "dir = './latest_sequence/bfs/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file read\n",
    "all_data = []\n",
    "sequence_length = []\n",
    "name = []\n",
    "for file in sorted(glob.glob(dir)):\n",
    "    name.append(file.split('/')[-1].replace('.txt', ''))\n",
    "    datasets = []\n",
    "    for f in open(file, 'r'):\n",
    "        f = f.replace(']', '').replace('[', '').replace('\\n','')\n",
    "        (u, v, w) = f.split(',')\n",
    "        datasets.append([int(u), int(v), float(w)])\n",
    "    sequence_length.append(len(datasets))\n",
    "    all_data.append(datasets)\n",
    "#all_data = np.array(all_data)\n",
    "all_data = np.array([np.array(arr) for arr in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, train_name, test_name = train_test_split(all_data, name, test_size=0.3)\n",
    "x_test, x_val, test_name, val_name = train_test_split(x_test, test_name, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name\n",
    "tr_names= []\n",
    "for name in train_name:\n",
    "    tr_names.append(name.split('-')[0].replace('graph', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max(sequence_length)\n",
    "n_features = 3\n",
    "batch_size = 32\n",
    "epochs = 300\n",
    "steps_per_epoch = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kullback_leibler_divergence(y_true, y_pred):\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1)\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
    "    return -1 * K.sum(y_true * K.log(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    loss1 = losses.mean_squared_error(y_true, y_pred)\n",
    "    loss2 = losses.KLD(y_true, y_pred)\n",
    "    return loss1 + loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def repeat_vector(args):\n",
    "    layer_to_repeat = args[0]\n",
    "    sequence_layer = args[1]\n",
    "    return RepeatVector(K.shape(sequence_layer)[1])(layer_to_repeat)\n",
    "    \n",
    "\n",
    "inputs = Input(shape=(None, 3))\n",
    "encoded = LSTM(128, return_sequences=True)(inputs)  #activation 안적으면 tanh\n",
    "#encoded = LSTM(128, return_sequences=True)(encoded)\n",
    "encoded = LSTM(64)(encoded)\n",
    "\n",
    "decoded = Lambda(repeat_vector, output_shape=(None, 64)) ([encoded, inputs]) # inputs의 shape[1] 만큼 encoded 를 반복 생성\n",
    "\n",
    "decoded = LSTM(64, return_sequences=True)(decoded)\n",
    "decoded = LSTM(128, return_sequences=True)(decoded)\n",
    "#decoded = LSTM(256, return_sequences=True)(decoded)\n",
    "decoded = TimeDistributed(Dense(3))(decoded)\n",
    "encoder = Model(inputs, encoded)\n",
    "\n",
    "lstm_autoencoder = Model(inputs, decoded)\n",
    "lstm_autoencoder.compile(loss=custom_loss, optimizer='adam')\n",
    "#lstm_autoencoder_500 = lstm_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(x_train):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        yield np.array([x_train[idx]]), np.array([x_train[idx]])\n",
    "        idx +=1\n",
    "        if idx >= len(x_train):\n",
    "            idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2352/2352 [==============================] - 45s 19ms/step - loss: 36.7772\n",
      "Epoch 2/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 35.7068\n",
      "Epoch 3/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 35.6346\n",
      "Epoch 4/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 31.1812\n",
      "Epoch 5/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 15.1742\n",
      "Epoch 6/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 13.0284\n",
      "Epoch 7/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 12.4345\n",
      "Epoch 8/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 11.1181\n",
      "Epoch 9/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 10.4062\n",
      "Epoch 10/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 9.9314\n",
      "Epoch 11/300\n",
      "2352/2352 [==============================] - 39s 16ms/step - loss: 9.1930\n",
      "Epoch 12/300\n",
      "2352/2352 [==============================] - 39s 16ms/step - loss: 8.5847\n",
      "Epoch 13/300\n",
      "2352/2352 [==============================] - 39s 16ms/step - loss: 8.5677\n",
      "Epoch 14/300\n",
      "2352/2352 [==============================] - 39s 17ms/step - loss: 7.7404\n",
      "Epoch 15/300\n",
      "2352/2352 [==============================] - 39s 17ms/step - loss: 6.6919\n",
      "Epoch 16/300\n",
      "2352/2352 [==============================] - 39s 17ms/step - loss: 6.8373\n",
      "Epoch 17/300\n",
      "2352/2352 [==============================] - 39s 16ms/step - loss: 5.9311\n",
      "Epoch 18/300\n",
      "2352/2352 [==============================] - 39s 17ms/step - loss: 5.3004\n",
      "Epoch 19/300\n",
      "2352/2352 [==============================] - 39s 16ms/step - loss: 5.1044\n",
      "Epoch 20/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 5.2829\n",
      "Epoch 21/300\n",
      "2352/2352 [==============================] - 43s 18ms/step - loss: 4.6748\n",
      "Epoch 22/300\n",
      "2352/2352 [==============================] - 41s 18ms/step - loss: 4.3635\n",
      "Epoch 23/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 3.9755\n",
      "Epoch 24/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 4.1952\n",
      "Epoch 25/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 3.5943\n",
      "Epoch 26/300\n",
      "2352/2352 [==============================] - 41s 18ms/step - loss: 3.3810\n",
      "Epoch 27/300\n",
      "2352/2352 [==============================] - 41s 18ms/step - loss: 3.6396\n",
      "Epoch 28/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 3.2466\n",
      "Epoch 29/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 3.2060\n",
      "Epoch 30/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 3.3260\n",
      "Epoch 31/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 3.2613\n",
      "Epoch 32/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 3.2008\n",
      "Epoch 33/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 2.7661\n",
      "Epoch 34/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 2.9660\n",
      "Epoch 35/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 2.6460\n",
      "Epoch 36/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 2.7213\n",
      "Epoch 37/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 2.6500\n",
      "Epoch 38/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 2.6898\n",
      "Epoch 39/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 2.3315\n",
      "Epoch 40/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 2.5316\n",
      "Epoch 41/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 2.3804\n",
      "Epoch 42/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 1.9835\n",
      "Epoch 43/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 2.2744\n",
      "Epoch 44/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 2.0381\n",
      "Epoch 45/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 2.1180\n",
      "Epoch 46/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 2.0709\n",
      "Epoch 47/300\n",
      "2352/2352 [==============================] - 41s 18ms/step - loss: 2.0061\n",
      "Epoch 48/300\n",
      "2352/2352 [==============================] - 44s 19ms/step - loss: 1.9749\n",
      "Epoch 49/300\n",
      "2352/2352 [==============================] - 45s 19ms/step - loss: 1.8774\n",
      "Epoch 50/300\n",
      "2352/2352 [==============================] - 45s 19ms/step - loss: 1.6958\n",
      "Epoch 51/300\n",
      "2352/2352 [==============================] - 45s 19ms/step - loss: 2.1047\n",
      "Epoch 52/300\n",
      "2352/2352 [==============================] - 45s 19ms/step - loss: 1.8614\n",
      "Epoch 53/300\n",
      "2352/2352 [==============================] - 45s 19ms/step - loss: 1.4396\n",
      "Epoch 54/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 1.5466\n",
      "Epoch 55/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 1.7025\n",
      "Epoch 56/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 1.5046\n",
      "Epoch 57/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 1.4419\n",
      "Epoch 58/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 1.2987\n",
      "Epoch 59/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 1.2523\n",
      "Epoch 60/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 1.5078\n",
      "Epoch 61/300\n",
      "2352/2352 [==============================] - 43s 18ms/step - loss: 1.3814\n",
      "Epoch 62/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 1.2422\n",
      "Epoch 63/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 1.2294\n",
      "Epoch 64/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 1.2272\n",
      "Epoch 65/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 1.1426\n",
      "Epoch 66/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 1.0328\n",
      "Epoch 67/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.9337\n",
      "Epoch 68/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 1.1430\n",
      "Epoch 69/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.8710\n",
      "Epoch 70/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.9791\n",
      "Epoch 71/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.8442\n",
      "Epoch 72/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.9436\n",
      "Epoch 73/300\n",
      "2352/2352 [==============================] - 41s 18ms/step - loss: 0.7181\n",
      "Epoch 74/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.7825\n",
      "Epoch 75/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.6799\n",
      "Epoch 76/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.7549\n",
      "Epoch 77/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.7408\n",
      "Epoch 78/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.6064\n",
      "Epoch 79/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.6879\n",
      "Epoch 80/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.5240\n",
      "Epoch 81/300\n",
      "2352/2352 [==============================] - 43s 18ms/step - loss: 0.5087\n",
      "Epoch 82/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.4953\n",
      "Epoch 83/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.8234\n",
      "Epoch 84/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.8370\n",
      "Epoch 85/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.5465\n",
      "Epoch 86/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.6308\n",
      "Epoch 87/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.5084\n",
      "Epoch 88/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.6583\n",
      "Epoch 89/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.5044\n",
      "Epoch 90/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.5057\n",
      "Epoch 91/300\n",
      "2352/2352 [==============================] - 41s 18ms/step - loss: 0.7409\n",
      "Epoch 92/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.6865\n",
      "Epoch 93/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.4514\n",
      "Epoch 94/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.5030\n",
      "Epoch 95/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.3537\n",
      "Epoch 96/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.4259\n",
      "Epoch 97/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.4158\n",
      "Epoch 98/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.3232\n",
      "Epoch 99/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.3780\n",
      "Epoch 100/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.4229\n",
      "Epoch 101/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.4835\n",
      "Epoch 102/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.4275\n",
      "Epoch 103/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.3739\n",
      "Epoch 104/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.3425\n",
      "Epoch 105/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.3369\n",
      "Epoch 106/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.4340\n",
      "Epoch 107/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.4494\n",
      "Epoch 108/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2773\n",
      "Epoch 109/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2917\n",
      "Epoch 110/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.3543\n",
      "Epoch 111/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.4005\n",
      "Epoch 112/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2719\n",
      "Epoch 113/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2485\n",
      "Epoch 114/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.3141\n",
      "Epoch 115/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2696\n",
      "Epoch 116/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2444\n",
      "Epoch 117/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2621\n",
      "Epoch 118/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2902\n",
      "Epoch 119/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.4137\n",
      "Epoch 120/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.3906\n",
      "Epoch 121/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2633\n",
      "Epoch 122/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2283\n",
      "Epoch 123/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2311\n",
      "Epoch 124/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2365\n",
      "Epoch 125/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2239\n",
      "Epoch 126/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2316\n",
      "Epoch 127/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2302\n",
      "Epoch 128/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2176\n",
      "Epoch 129/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2085\n",
      "Epoch 130/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1986\n",
      "Epoch 131/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1938\n",
      "Epoch 132/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2239\n",
      "Epoch 133/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2652\n",
      "Epoch 134/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.4396\n",
      "Epoch 135/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1795\n",
      "Epoch 136/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1736\n",
      "Epoch 137/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1920\n",
      "Epoch 138/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1939\n",
      "Epoch 139/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1865\n",
      "Epoch 140/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2446\n",
      "Epoch 141/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2935\n",
      "Epoch 142/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2135\n",
      "Epoch 143/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1807\n",
      "Epoch 144/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1744\n",
      "Epoch 145/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1796\n",
      "Epoch 146/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2077\n",
      "Epoch 147/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1558\n",
      "Epoch 148/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1604\n",
      "Epoch 149/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1714\n",
      "Epoch 150/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1765\n",
      "Epoch 151/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.3629\n",
      "Epoch 152/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2489\n",
      "Epoch 153/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1578\n",
      "Epoch 154/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1528\n",
      "Epoch 155/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1698\n",
      "Epoch 156/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2020\n",
      "Epoch 157/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1466\n",
      "Epoch 158/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1480\n",
      "Epoch 159/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1619\n",
      "Epoch 160/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1576\n",
      "Epoch 161/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1728\n",
      "Epoch 162/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2604\n",
      "Epoch 163/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1151\n",
      "Epoch 164/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1509\n",
      "Epoch 165/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2098\n",
      "Epoch 166/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2610\n",
      "Epoch 167/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1286\n",
      "Epoch 168/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1328\n",
      "Epoch 169/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1460\n",
      "Epoch 170/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1751\n",
      "Epoch 171/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1267\n",
      "Epoch 172/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1406\n",
      "Epoch 173/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1462\n",
      "Epoch 174/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1213\n",
      "Epoch 175/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1367\n",
      "Epoch 176/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1326\n",
      "Epoch 177/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.4703\n",
      "Epoch 178/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2081\n",
      "Epoch 179/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1960\n",
      "Epoch 180/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2294\n",
      "Epoch 181/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.1755\n",
      "Epoch 182/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2470\n",
      "Epoch 183/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1149\n",
      "Epoch 184/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1227\n",
      "Epoch 185/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1335\n",
      "Epoch 186/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1392\n",
      "Epoch 187/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1424\n",
      "Epoch 188/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1324\n",
      "Epoch 189/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1285\n",
      "Epoch 190/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1333\n",
      "Epoch 191/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1274\n",
      "Epoch 192/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1295\n",
      "Epoch 193/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1215\n",
      "Epoch 194/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1338\n",
      "Epoch 195/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1381\n",
      "Epoch 196/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1141\n",
      "Epoch 197/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1223\n",
      "Epoch 198/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1188\n",
      "Epoch 199/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1185\n",
      "Epoch 200/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1876\n",
      "Epoch 201/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1083\n",
      "Epoch 202/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1012\n",
      "Epoch 203/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1081\n",
      "Epoch 204/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1394\n",
      "Epoch 205/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1660\n",
      "Epoch 206/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0964\n",
      "Epoch 207/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1111\n",
      "Epoch 208/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1191\n",
      "Epoch 209/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1067\n",
      "Epoch 210/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1156\n",
      "Epoch 211/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1074\n",
      "Epoch 212/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1108\n",
      "Epoch 213/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1057\n",
      "Epoch 214/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1076\n",
      "Epoch 215/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1084\n",
      "Epoch 216/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1008\n",
      "Epoch 217/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1116\n",
      "Epoch 218/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1114\n",
      "Epoch 219/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1067\n",
      "Epoch 220/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0975\n",
      "Epoch 221/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1024\n",
      "Epoch 222/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1007\n",
      "Epoch 223/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0990\n",
      "Epoch 224/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1074\n",
      "Epoch 225/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0990\n",
      "Epoch 226/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1338\n",
      "Epoch 227/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1912\n",
      "Epoch 228/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2610\n",
      "Epoch 229/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.2655\n",
      "Epoch 230/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0835\n",
      "Epoch 231/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0976\n",
      "Epoch 232/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1092\n",
      "Epoch 233/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1046\n",
      "Epoch 234/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1070\n",
      "Epoch 235/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1048\n",
      "Epoch 236/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0970\n",
      "Epoch 237/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.1033\n",
      "Epoch 238/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0980\n",
      "Epoch 239/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0948\n",
      "Epoch 240/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.0970\n",
      "Epoch 241/300\n",
      "2352/2352 [==============================] - 41s 17ms/step - loss: 0.0953\n",
      "Epoch 242/300\n",
      "2352/2352 [==============================] - 43s 18ms/step - loss: 0.0918\n",
      "Epoch 243/300\n",
      "2352/2352 [==============================] - 43s 18ms/step - loss: 0.0915\n",
      "Epoch 244/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0985\n",
      "Epoch 245/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0967\n",
      "Epoch 246/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0906\n",
      "Epoch 247/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0846\n",
      "Epoch 248/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0934\n",
      "Epoch 249/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0888\n",
      "Epoch 250/300\n",
      "2352/2352 [==============================] - 43s 18ms/step - loss: 0.0914\n",
      "Epoch 251/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0969\n",
      "Epoch 252/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0962\n",
      "Epoch 253/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0881\n",
      "Epoch 254/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0797\n",
      "Epoch 255/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0876\n",
      "Epoch 256/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.1001\n",
      "Epoch 257/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0903\n",
      "Epoch 258/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0825\n",
      "Epoch 259/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0891\n",
      "Epoch 260/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0891\n",
      "Epoch 261/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0814\n",
      "Epoch 262/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0868\n",
      "Epoch 263/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0971\n",
      "Epoch 264/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0829\n",
      "Epoch 265/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0823\n",
      "Epoch 266/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0821\n",
      "Epoch 267/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0877\n",
      "Epoch 268/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0854\n",
      "Epoch 269/300\n",
      "2352/2352 [==============================] - 43s 18ms/step - loss: 0.1023\n",
      "Epoch 270/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0716\n",
      "Epoch 271/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0771\n",
      "Epoch 272/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0911\n",
      "Epoch 273/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0829\n",
      "Epoch 274/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0789\n",
      "Epoch 275/300\n",
      "2352/2352 [==============================] - 43s 18ms/step - loss: 0.0889\n",
      "Epoch 276/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0864\n",
      "Epoch 277/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0808\n",
      "Epoch 278/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.1019\n",
      "Epoch 279/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.2605\n",
      "Epoch 280/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.1338\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2352/2352 [==============================] - 41s 18ms/step - loss: 0.0658\n",
      "Epoch 282/300\n",
      "2352/2352 [==============================] - 41s 18ms/step - loss: 0.0766\n",
      "Epoch 283/300\n",
      "2352/2352 [==============================] - 42s 18ms/step - loss: 0.0753\n",
      "Epoch 284/300\n",
      "2352/2352 [==============================] - 41s 18ms/step - loss: 0.0996\n",
      "Epoch 285/300\n",
      "2352/2352 [==============================] - 41s 18ms/step - loss: 0.1257\n",
      "Epoch 286/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0711\n",
      "Epoch 287/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0779\n",
      "Epoch 288/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0845\n",
      "Epoch 289/300\n",
      "2352/2352 [==============================] - 39s 17ms/step - loss: 0.0866\n",
      "Epoch 290/300\n",
      "2352/2352 [==============================] - 39s 17ms/step - loss: 0.0788\n",
      "Epoch 291/300\n",
      "2352/2352 [==============================] - 39s 17ms/step - loss: 0.0774\n",
      "Epoch 292/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0857\n",
      "Epoch 293/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0808\n",
      "Epoch 294/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0723\n",
      "Epoch 295/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0777\n",
      "Epoch 296/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0851\n",
      "Epoch 297/300\n",
      "2352/2352 [==============================] - 39s 17ms/step - loss: 0.0782\n",
      "Epoch 298/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0712\n",
      "Epoch 299/300\n",
      "2352/2352 [==============================] - 40s 17ms/step - loss: 0.0780\n",
      "Epoch 300/300\n",
      "2352/2352 [==============================] - 39s 17ms/step - loss: 0.0741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f36d357cfd0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_autoencoder.fit_generator(train_generator(x_train), epochs=epochs, steps_per_epoch=steps_per_epoch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model save\n",
    "lstm_autoencoder.save('model/lstm_autoencoder_custom_loss_bfs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function:custom_loss",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-081974129c73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model/lstm_autoencoder_custom_loss_bfs.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(h5dict, custom_objects, compile)\u001b[0m\n\u001b[1;32m    333\u001b[0m                       \u001b[0mweighted_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                       \u001b[0mloss_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                       sample_weight_mode=sample_weight_mode)\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;31m# Set optimizer weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss_function\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/losses.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/losses.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m    112\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                                     printable_module_name='loss function')\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 167\u001b[0;31m                                  ':' + function_name)\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown loss function:custom_loss"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('model/lstm_autoencoder_custom_loss_bfs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = lstm_autoencoder.to_json()\n",
    "with open('model/lstm_autoencoder_custom_loss_bfs.json', 'w') as file:\n",
    "    file.write(model_json)\n",
    "lstm_autoencoder.save_weights('model/weights_lstm_autoencoder_custom_loss_bfs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_from_json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-3731a7652eb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model/lstm_autoencoder_custom_loss_bfs.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_from_json' is not defined"
     ]
    }
   ],
   "source": [
    "model = model_from_json(open('model/lstm_autoencoder_custom_loss_bfs.json').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = lstm_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3042766420199887\n"
     ]
    }
   ],
   "source": [
    "mean= 0\n",
    "for xt in x_test:\n",
    "    xt = xt.reshape(1, xt.shape[0], xt.shape[1])\n",
    "    out = loaded_model.predict(xt)\n",
    "    mean += ((xt-out)**2).mean(axis=None)\n",
    "print(mean/len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(loaded_model.input, loaded_model.layers[3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = x_test[0].reshape(1, x_test[0].shape[0], x_test[0].shape[1])\n",
    "latent_vector = []\n",
    "for x in x_test:\n",
    "    x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "    latent_vector.append(encoder.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latent_vector = np.array(latent_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
