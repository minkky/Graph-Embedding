{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob, os\n",
    "from keras import layers as ly\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Lambda\n",
    "from keras import losses\n",
    "from keras.models import model_from_json\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir = './sequence/*'\n",
    "dir = './latest_sequence/bfs-character/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file read\n",
    "all_names = []\n",
    "all_data = []\n",
    "sequence_length = []\n",
    "alpha = list(string.ascii_uppercase)\n",
    "data_length = len(glob.glob(dir))\n",
    "file_predix = './latest_sequence/bfs-character/graph'\n",
    "for index in range(data_length):\n",
    "    filename = file_predix + str(index) + \"-*\"\n",
    "    files = glob.glob(filename)\n",
    "    for file in files:\n",
    "        datasets = []\n",
    "        all_names.append(file.split('/')[-1].replace('.txt', ''))\n",
    "        for rf in open(file, 'r'):\n",
    "            (u, v, w) = rf[1:-2].split(', ')\n",
    "            datasets.append([alpha.index(u[1])+1, alpha.index(v[1]) +1, float(w)])\n",
    "        sequence_length.append(len(datasets))\n",
    "        all_data.append(datasets)\n",
    "all_data = np.array([np.array(arr) for arr in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, train_name, test_name = train_test_split(all_data, all_names, test_size=0.3)\n",
    "x_test, x_val, test_name, val_name = train_test_split(x_test, test_name, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name\n",
    "tr_names= []\n",
    "for name in train_name:\n",
    "    tr_names.append(name.split('-')[0].replace('graph', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max(sequence_length)\n",
    "n_features = 3\n",
    "batch_size = 32\n",
    "epochs = 500\n",
    "steps_per_epoch = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    loss1 = losses.mean_squared_error(y_true, y_pred)\n",
    "    loss2 = losses.categorical_crossentropy(y_true, y_pred)\n",
    "    return loss1 * 0.7 + loss2 * 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def repeat_vector(args):\n",
    "    layer_to_repeat = args[0]\n",
    "    sequence_layer = args[1]\n",
    "    return RepeatVector(K.shape(sequence_layer)[1])(layer_to_repeat)\n",
    "    \n",
    "\n",
    "inputs = Input(shape=(None, 3))\n",
    "encoded = LSTM(128, return_sequences=True)(inputs)  #activation 안적으면 tanh\n",
    "encoded = LSTM(64)(encoded)\n",
    "\n",
    "decoded = Lambda(repeat_vector, output_shape=(None, 64)) ([encoded, inputs]) # inputs의 shape[1] 만큼 encoded 를 반복 생성\n",
    "\n",
    "decoded = LSTM(64, return_sequences=True)(decoded)\n",
    "decoded = LSTM(128, return_sequences=True)(decoded)\n",
    "decoded = TimeDistributed(Dense(3))(decoded)\n",
    "encoder = Model(inputs, encoded)\n",
    "\n",
    "lstm_autoencoder = Model(inputs, decoded)\n",
    "lstm_autoencoder.compile(loss=custom_loss, optimizer='adam')#lr=1e-2, decay=0.9))\n",
    "#lstm_autoencoder_500 = lstm_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_generator(x_val):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        yield np.array([x_val[idx]]), np.array([x_val[idx]])\n",
    "        idx += 1\n",
    "        if idx >= len(x_val):\n",
    "            idx = 0\n",
    "\n",
    "def train_generator(x_train):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        yield np.array([x_train[idx]]), np.array([x_train[idx]])\n",
    "        idx += 1\n",
    "        if idx >= len(x_train):\n",
    "            idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "6468/6468 [==============================] - 61s 10ms/step - loss: 28.5503 - val_loss: 24.2984\n",
      "Epoch 2/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 20.4023 - val_loss: 20.1032\n",
      "Epoch 3/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 17.5402 - val_loss: 16.5758\n",
      "Epoch 4/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 15.2827 - val_loss: 15.3065\n",
      "Epoch 5/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 14.0901 - val_loss: 14.3841\n",
      "Epoch 6/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 13.2006 - val_loss: 13.3820\n",
      "Epoch 7/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 12.6601 - val_loss: 12.7284\n",
      "Epoch 8/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 12.0285 - val_loss: 12.0571\n",
      "Epoch 9/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 11.4082 - val_loss: 11.9274\n",
      "Epoch 10/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 10.9447 - val_loss: 11.5044\n",
      "Epoch 11/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 10.5562 - val_loss: 10.9280\n",
      "Epoch 12/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 10.3118 - val_loss: 10.7713\n",
      "Epoch 13/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 10.0361 - val_loss: 10.3469\n",
      "Epoch 14/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 9.7627 - val_loss: 10.2206\n",
      "Epoch 15/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 9.5279 - val_loss: 10.1101\n",
      "Epoch 16/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 9.3186 - val_loss: 9.8860\n",
      "Epoch 17/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 9.1534 - val_loss: 9.5861\n",
      "Epoch 18/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 9.0109 - val_loss: 9.3772\n",
      "Epoch 19/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 8.7293 - val_loss: 9.3991\n",
      "Epoch 20/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 8.6289 - val_loss: 9.1393\n",
      "Epoch 21/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 8.4974 - val_loss: 9.1573\n",
      "Epoch 22/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 8.5257 - val_loss: 9.0745\n",
      "Epoch 23/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 8.3046 - val_loss: 8.8973\n",
      "Epoch 24/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 8.2904 - val_loss: 8.8532\n",
      "Epoch 25/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 8.1359 - val_loss: 8.6943\n",
      "Epoch 26/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 8.0995 - val_loss: 8.6637\n",
      "Epoch 27/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 8.0078 - val_loss: 8.6462\n",
      "Epoch 28/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.9284 - val_loss: 8.5758\n",
      "Epoch 29/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.8816 - val_loss: 8.5114\n",
      "Epoch 30/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.8021 - val_loss: 8.2872\n",
      "Epoch 31/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.7823 - val_loss: 8.2433\n",
      "Epoch 32/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.7438 - val_loss: 8.2958\n",
      "Epoch 33/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.6744 - val_loss: 8.1883\n",
      "Epoch 34/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.7576 - val_loss: 8.0669\n",
      "Epoch 35/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.6136 - val_loss: 8.3272\n",
      "Epoch 36/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.5660 - val_loss: 8.1625\n",
      "Epoch 37/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.5796 - val_loss: 8.0532\n",
      "Epoch 38/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.5545 - val_loss: 7.9556\n",
      "Epoch 39/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.5182 - val_loss: 8.3620\n",
      "Epoch 40/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.5038 - val_loss: 7.9723\n",
      "Epoch 41/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.5050 - val_loss: 7.9245\n",
      "Epoch 42/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.4636 - val_loss: 7.9613\n",
      "Epoch 43/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.4450 - val_loss: 7.9254\n",
      "Epoch 44/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.4433 - val_loss: 7.9377\n",
      "Epoch 45/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.4485 - val_loss: 7.9019\n",
      "Epoch 46/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.4085 - val_loss: 7.8040\n",
      "Epoch 47/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.4315 - val_loss: 7.8847\n",
      "Epoch 48/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.3946 - val_loss: 8.0718\n",
      "Epoch 49/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.3704 - val_loss: 7.8061\n",
      "Epoch 50/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.3699 - val_loss: 7.9180\n",
      "Epoch 51/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.3661 - val_loss: 7.7475\n",
      "Epoch 52/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.3488 - val_loss: 7.7726\n",
      "Epoch 53/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.3434 - val_loss: 7.7648\n",
      "Epoch 54/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.3405 - val_loss: 7.7633\n",
      "Epoch 55/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.3458 - val_loss: 7.7311\n",
      "Epoch 56/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.3168 - val_loss: 7.7462\n",
      "Epoch 57/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.3043 - val_loss: 7.8615\n",
      "Epoch 58/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.3038 - val_loss: 7.7886\n",
      "Epoch 59/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.3062 - val_loss: 7.7656\n",
      "Epoch 60/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2938 - val_loss: 7.7305\n",
      "Epoch 61/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.3499 - val_loss: 7.7529\n",
      "Epoch 62/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2708 - val_loss: 7.7189\n",
      "Epoch 63/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2810 - val_loss: 7.6958\n",
      "Epoch 64/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2722 - val_loss: 7.6917\n",
      "Epoch 65/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2613 - val_loss: 7.6521\n",
      "Epoch 66/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2649 - val_loss: 7.6957\n",
      "Epoch 67/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2711 - val_loss: 7.9217\n",
      "Epoch 68/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2435 - val_loss: 7.7263\n",
      "Epoch 69/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2542 - val_loss: 7.6742\n",
      "Epoch 70/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2442 - val_loss: 7.6900\n",
      "Epoch 71/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2355 - val_loss: 7.6376\n",
      "Epoch 72/300\n",
      "6468/6468 [==============================] - 61s 9ms/step - loss: 7.2356 - val_loss: 7.6628\n",
      "Epoch 73/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2384 - val_loss: 7.6639\n",
      "Epoch 74/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2169 - val_loss: 7.6439\n",
      "Epoch 75/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2258 - val_loss: 7.7245\n",
      "Epoch 76/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2291 - val_loss: 7.6661\n",
      "Epoch 77/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2818 - val_loss: 7.6691\n",
      "Epoch 78/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.2077 - val_loss: 7.6283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.2188 - val_loss: 7.6489\n",
      "Epoch 80/300\n",
      "6468/6468 [==============================] - 58s 9ms/step - loss: 7.2050 - val_loss: 7.8172\n",
      "Epoch 81/300\n",
      "6468/6468 [==============================] - 58s 9ms/step - loss: 7.2283 - val_loss: 7.6061\n",
      "Epoch 82/300\n",
      "6468/6468 [==============================] - 58s 9ms/step - loss: 7.2013 - val_loss: 7.7030\n",
      "Epoch 83/300\n",
      "6468/6468 [==============================] - 58s 9ms/step - loss: 7.2283 - val_loss: 7.5996\n",
      "Epoch 84/300\n",
      "6468/6468 [==============================] - 58s 9ms/step - loss: 7.1904 - val_loss: 7.6250\n",
      "Epoch 85/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.2170 - val_loss: 7.6722\n",
      "Epoch 86/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1933 - val_loss: 7.6680\n",
      "Epoch 87/300\n",
      "6468/6468 [==============================] - 58s 9ms/step - loss: 7.1853 - val_loss: 7.5977\n",
      "Epoch 88/300\n",
      "6468/6468 [==============================] - 58s 9ms/step - loss: 7.1991 - val_loss: 7.5851\n",
      "Epoch 89/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1909 - val_loss: 7.6119\n",
      "Epoch 90/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1817 - val_loss: 7.6715\n",
      "Epoch 91/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1921 - val_loss: 7.6228\n",
      "Epoch 92/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1769 - val_loss: 7.6026\n",
      "Epoch 93/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1754 - val_loss: 7.6341\n",
      "Epoch 94/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1891 - val_loss: 7.5639\n",
      "Epoch 95/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1809 - val_loss: 7.6983\n",
      "Epoch 96/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1759 - val_loss: 7.6194\n",
      "Epoch 97/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1656 - val_loss: 7.5540\n",
      "Epoch 98/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1628 - val_loss: 7.5826\n",
      "Epoch 99/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1710 - val_loss: 7.6279\n",
      "Epoch 100/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1702 - val_loss: 7.6558\n",
      "Epoch 101/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1564 - val_loss: 7.6049\n",
      "Epoch 102/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1736 - val_loss: 7.6408\n",
      "Epoch 103/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1555 - val_loss: 7.6259\n",
      "Epoch 104/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1605 - val_loss: 7.6749\n",
      "Epoch 105/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1613 - val_loss: 7.5931\n",
      "Epoch 106/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1545 - val_loss: 7.6546\n",
      "Epoch 107/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1535 - val_loss: 7.6237\n",
      "Epoch 108/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1479 - val_loss: 7.6228\n",
      "Epoch 109/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1533 - val_loss: 7.5977\n",
      "Epoch 110/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1385 - val_loss: 7.6111\n",
      "Epoch 111/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1441 - val_loss: 7.5439\n",
      "Epoch 112/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1451 - val_loss: 7.6174\n",
      "Epoch 113/300\n",
      "6468/6468 [==============================] - 62s 10ms/step - loss: 7.1391 - val_loss: 7.6269\n",
      "Epoch 114/300\n",
      "6468/6468 [==============================] - 63s 10ms/step - loss: 7.1598 - val_loss: 7.5415\n",
      "Epoch 115/300\n",
      "6468/6468 [==============================] - 63s 10ms/step - loss: 7.1496 - val_loss: 7.6561\n",
      "Epoch 116/300\n",
      "6468/6468 [==============================] - 63s 10ms/step - loss: 7.1438 - val_loss: 7.5530\n",
      "Epoch 117/300\n",
      "6468/6468 [==============================] - 64s 10ms/step - loss: 7.1331 - val_loss: 7.6245\n",
      "Epoch 118/300\n",
      "6468/6468 [==============================] - 63s 10ms/step - loss: 7.1463 - val_loss: 7.5845\n",
      "Epoch 119/300\n",
      "6468/6468 [==============================] - 64s 10ms/step - loss: 7.1270 - val_loss: 7.5478\n",
      "Epoch 120/300\n",
      "6468/6468 [==============================] - 63s 10ms/step - loss: 7.1419 - val_loss: 7.5575\n",
      "Epoch 121/300\n",
      "6468/6468 [==============================] - 62s 10ms/step - loss: 7.1297 - val_loss: 7.7850\n",
      "Epoch 122/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1451 - val_loss: 7.5992\n",
      "Epoch 123/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1305 - val_loss: 7.5758\n",
      "Epoch 124/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1269 - val_loss: 7.5708\n",
      "Epoch 125/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1354 - val_loss: 7.6383\n",
      "Epoch 126/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1284 - val_loss: 7.5443\n",
      "Epoch 127/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1306 - val_loss: 7.6461\n",
      "Epoch 128/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1253 - val_loss: 7.5224\n",
      "Epoch 129/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1352 - val_loss: 7.6094\n",
      "Epoch 130/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1267 - val_loss: 7.5609\n",
      "Epoch 131/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1240 - val_loss: 7.5627\n",
      "Epoch 132/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1243 - val_loss: 7.5433\n",
      "Epoch 133/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1175 - val_loss: 7.5555\n",
      "Epoch 134/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1295 - val_loss: 7.5076\n",
      "Epoch 135/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1617 - val_loss: 7.5840\n",
      "Epoch 136/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1160 - val_loss: 7.5678\n",
      "Epoch 137/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1169 - val_loss: 7.5685\n",
      "Epoch 138/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1229 - val_loss: 7.5516\n",
      "Epoch 139/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1178 - val_loss: 7.5131\n",
      "Epoch 140/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1055 - val_loss: 7.5935\n",
      "Epoch 141/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1124 - val_loss: 7.5720\n",
      "Epoch 142/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1159 - val_loss: 7.5507\n",
      "Epoch 143/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1107 - val_loss: 7.5545\n",
      "Epoch 144/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1133 - val_loss: 7.5301\n",
      "Epoch 145/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1155 - val_loss: 7.5832\n",
      "Epoch 146/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1120 - val_loss: 7.8565\n",
      "Epoch 147/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1181 - val_loss: 7.6319\n",
      "Epoch 148/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1081 - val_loss: 7.5455\n",
      "Epoch 149/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1049 - val_loss: 7.5290\n",
      "Epoch 150/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1106 - val_loss: 7.6224\n",
      "Epoch 151/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1095 - val_loss: 7.5762\n",
      "Epoch 152/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1065 - val_loss: 7.6628\n",
      "Epoch 153/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1059 - val_loss: 7.6047\n",
      "Epoch 154/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.0967 - val_loss: 7.5514\n",
      "Epoch 155/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.1041 - val_loss: 7.5956\n",
      "Epoch 156/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1075 - val_loss: 7.6863\n",
      "Epoch 157/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0932 - val_loss: 7.5378\n",
      "Epoch 158/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0972 - val_loss: 7.5362\n",
      "Epoch 159/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1013 - val_loss: 7.5799\n",
      "Epoch 160/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0949 - val_loss: 7.5234\n",
      "Epoch 161/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1045 - val_loss: 7.5702\n",
      "Epoch 162/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1205 - val_loss: 7.4861\n",
      "Epoch 163/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0996 - val_loss: 7.5440\n",
      "Epoch 164/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1236 - val_loss: 7.7552\n",
      "Epoch 165/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0906 - val_loss: 7.5311\n",
      "Epoch 166/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0991 - val_loss: 7.5285\n",
      "Epoch 167/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0977 - val_loss: 7.4818\n",
      "Epoch 168/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1025 - val_loss: 7.5527\n",
      "Epoch 169/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0920 - val_loss: 7.5282\n",
      "Epoch 170/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0970 - val_loss: 7.5262\n",
      "Epoch 171/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0896 - val_loss: 7.5722\n",
      "Epoch 172/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0933 - val_loss: 7.6239\n",
      "Epoch 173/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0903 - val_loss: 7.5203\n",
      "Epoch 174/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1185 - val_loss: 7.4937\n",
      "Epoch 175/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0836 - val_loss: 7.6054\n",
      "Epoch 176/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0935 - val_loss: 7.6239\n",
      "Epoch 177/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0951 - val_loss: 7.5444\n",
      "Epoch 178/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0853 - val_loss: 7.5978\n",
      "Epoch 179/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0945 - val_loss: 7.5107\n",
      "Epoch 180/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0880 - val_loss: 7.5424\n",
      "Epoch 181/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0945 - val_loss: 7.5211\n",
      "Epoch 182/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0879 - val_loss: 7.5273\n",
      "Epoch 183/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0875 - val_loss: 7.6505\n",
      "Epoch 184/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1089 - val_loss: 7.5420\n",
      "Epoch 185/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0814 - val_loss: 7.5332\n",
      "Epoch 186/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0871 - val_loss: 7.5549\n",
      "Epoch 187/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0868 - val_loss: 7.5672\n",
      "Epoch 188/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0861 - val_loss: 7.5505\n",
      "Epoch 189/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0795 - val_loss: 7.5328\n",
      "Epoch 190/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0889 - val_loss: 7.5677\n",
      "Epoch 191/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0845 - val_loss: 7.5771\n",
      "Epoch 192/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0784 - val_loss: 7.5786\n",
      "Epoch 193/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0833 - val_loss: 7.5553\n",
      "Epoch 194/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0842 - val_loss: 7.5315\n",
      "Epoch 195/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0765 - val_loss: 7.5839\n",
      "Epoch 196/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0820 - val_loss: 7.6437\n",
      "Epoch 197/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0846 - val_loss: 7.5218\n",
      "Epoch 198/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0803 - val_loss: 7.5375\n",
      "Epoch 199/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0777 - val_loss: 7.5148\n",
      "Epoch 200/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0781 - val_loss: 7.5066\n",
      "Epoch 201/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0879 - val_loss: 7.5466\n",
      "Epoch 202/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0721 - val_loss: 7.5657\n",
      "Epoch 203/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0767 - val_loss: 7.6361\n",
      "Epoch 204/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0856 - val_loss: 7.5035\n",
      "Epoch 205/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0844 - val_loss: 7.5523\n",
      "Epoch 206/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0717 - val_loss: 7.5404\n",
      "Epoch 207/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0855 - val_loss: 7.5412\n",
      "Epoch 208/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0734 - val_loss: 7.6032\n",
      "Epoch 209/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0867 - val_loss: 8.2701\n",
      "Epoch 210/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1308 - val_loss: 7.5437\n",
      "Epoch 211/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0676 - val_loss: 7.5802\n",
      "Epoch 212/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0739 - val_loss: 7.5098\n",
      "Epoch 213/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0693 - val_loss: 7.6741\n",
      "Epoch 214/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0826 - val_loss: 7.5141\n",
      "Epoch 215/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0731 - val_loss: 7.5103\n",
      "Epoch 216/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0672 - val_loss: 7.5490\n",
      "Epoch 217/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0796 - val_loss: 7.5473\n",
      "Epoch 218/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0953 - val_loss: 7.4993\n",
      "Epoch 219/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0925 - val_loss: 7.4977\n",
      "Epoch 220/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0944 - val_loss: 7.6362\n",
      "Epoch 221/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0683 - val_loss: 7.5131\n",
      "Epoch 222/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0763 - val_loss: 7.5573\n",
      "Epoch 223/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0639 - val_loss: 7.6417\n",
      "Epoch 224/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0720 - val_loss: 7.4972\n",
      "Epoch 225/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0729 - val_loss: 7.5235\n",
      "Epoch 226/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0656 - val_loss: 7.6001\n",
      "Epoch 227/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0689 - val_loss: 7.5133\n",
      "Epoch 228/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0686 - val_loss: 7.5336\n",
      "Epoch 229/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0638 - val_loss: 7.5184\n",
      "Epoch 230/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0661 - val_loss: 7.5366\n",
      "Epoch 231/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0710 - val_loss: 7.4962\n",
      "Epoch 232/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0600 - val_loss: 7.5803\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0630 - val_loss: 7.5310\n",
      "Epoch 234/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0697 - val_loss: 7.5044\n",
      "Epoch 235/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0640 - val_loss: 7.5096\n",
      "Epoch 236/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0792 - val_loss: 7.6033\n",
      "Epoch 237/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0582 - val_loss: 7.5080\n",
      "Epoch 238/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0585 - val_loss: 7.5120\n",
      "Epoch 239/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0617 - val_loss: 7.5332\n",
      "Epoch 240/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0645 - val_loss: 7.5347\n",
      "Epoch 241/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0602 - val_loss: 7.5482\n",
      "Epoch 242/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0645 - val_loss: 7.5758\n",
      "Epoch 243/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0700 - val_loss: 7.5014\n",
      "Epoch 244/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0582 - val_loss: 7.5119\n",
      "Epoch 245/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0593 - val_loss: 7.5642\n",
      "Epoch 246/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0629 - val_loss: 7.5488\n",
      "Epoch 247/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0612 - val_loss: 7.5316\n",
      "Epoch 248/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0548 - val_loss: 7.5101\n",
      "Epoch 249/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0644 - val_loss: 7.5225\n",
      "Epoch 250/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0695 - val_loss: 7.4966\n",
      "Epoch 251/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0679 - val_loss: 7.6433\n",
      "Epoch 252/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0645 - val_loss: 7.5266\n",
      "Epoch 253/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0639 - val_loss: 7.5502\n",
      "Epoch 254/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0616 - val_loss: 7.4935\n",
      "Epoch 255/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0596 - val_loss: 7.5809\n",
      "Epoch 256/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0670 - val_loss: 7.5393\n",
      "Epoch 257/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0570 - val_loss: 7.5313\n",
      "Epoch 258/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0591 - val_loss: 7.5060\n",
      "Epoch 259/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0527 - val_loss: 7.6048\n",
      "Epoch 260/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0526 - val_loss: 7.5107\n",
      "Epoch 261/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0677 - val_loss: 7.5159\n",
      "Epoch 262/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0502 - val_loss: 7.5413\n",
      "Epoch 263/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0615 - val_loss: 7.5798\n",
      "Epoch 264/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0571 - val_loss: 7.5160\n",
      "Epoch 265/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0790 - val_loss: 8.6575\n",
      "Epoch 266/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.1001 - val_loss: 7.6645\n",
      "Epoch 267/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0572 - val_loss: 7.5485\n",
      "Epoch 268/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0584 - val_loss: 7.5226\n",
      "Epoch 269/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0535 - val_loss: 7.5211\n",
      "Epoch 270/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0648 - val_loss: 7.5211\n",
      "Epoch 271/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0579 - val_loss: 7.5152\n",
      "Epoch 272/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0522 - val_loss: 7.5197\n",
      "Epoch 273/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0643 - val_loss: 7.5948\n",
      "Epoch 274/300\n",
      "6468/6468 [==============================] - 60s 9ms/step - loss: 7.0559 - val_loss: 7.5068\n",
      "Epoch 275/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0500 - val_loss: 7.4989\n",
      "Epoch 276/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0521 - val_loss: 7.4987\n",
      "Epoch 277/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0572 - val_loss: 7.5013\n",
      "Epoch 278/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0484 - val_loss: 7.5365\n",
      "Epoch 279/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0536 - val_loss: 7.5759\n",
      "Epoch 280/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0520 - val_loss: 7.5076\n",
      "Epoch 281/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0539 - val_loss: 7.5336\n",
      "Epoch 282/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0517 - val_loss: 7.4997\n",
      "Epoch 283/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0530 - val_loss: 7.5306\n",
      "Epoch 284/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0561 - val_loss: 7.5017\n",
      "Epoch 285/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0468 - val_loss: 7.5084\n",
      "Epoch 286/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0549 - val_loss: 7.5712\n",
      "Epoch 287/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0671 - val_loss: 7.5072\n",
      "Epoch 288/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0502 - val_loss: 7.4831\n",
      "Epoch 289/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0531 - val_loss: 7.4799\n",
      "Epoch 290/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0509 - val_loss: 7.4785\n",
      "Epoch 291/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0447 - val_loss: 7.5517\n",
      "Epoch 292/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0491 - val_loss: 7.6020\n",
      "Epoch 293/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0539 - val_loss: 7.5498\n",
      "Epoch 294/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0482 - val_loss: 7.4948\n",
      "Epoch 295/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0493 - val_loss: 7.5241\n",
      "Epoch 296/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0519 - val_loss: 7.5931\n",
      "Epoch 297/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0458 - val_loss: 7.4910\n",
      "Epoch 298/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0558 - val_loss: 7.5069\n",
      "Epoch 299/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0467 - val_loss: 7.5156\n",
      "Epoch 300/300\n",
      "6468/6468 [==============================] - 59s 9ms/step - loss: 7.0518 - val_loss: 7.5094\n"
     ]
    }
   ],
   "source": [
    "hist = lstm_autoencoder.fit_generator(train_generator(x_train), epochs=300, steps_per_epoch=steps_per_epoch, verbose=1, validation_steps=len(x_val), validation_data=val_generator(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = lstm_autoencoder.to_json()\n",
    "filename = 'last_mse_lstmae_cce1'  #input('filename: ') #\n",
    "with open('model_save/mse_cce_models/' + filename + '.json', 'w') as file:\n",
    "    file.write(model_json)\n",
    "lstm_autoencoder.save_weights('model_save/mse_cce_models/weights_' +  filename + '.h5')\n",
    "\n",
    "with open('model_save/mse_cce_models/cce1_histroy.json', 'w') as f:\n",
    "    json.dump(hist.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "loss_ax.plot(hist.history['val_loss'], 'b', label='val loss')\n",
    "loss_ax.plot(hist.history['loss'], 'r', label='train loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"last_mse_lstmae_cce\"\n",
    "loaded_model = model_from_json(open('model_save/mse_cce_models/' +filename + '.json').read())\n",
    "loaded_model.load_weights('model_save/mse_cce_models/weights_' + filename + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = lstm_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8349219160979637\n"
     ]
    }
   ],
   "source": [
    "mean= 0\n",
    "for xt in x_test:\n",
    "    xt = xt.reshape(1, xt.shape[0], xt.shape[1])\n",
    "    out = loaded_model.predict(xt)\n",
    "    mean += ((xt-out)**2).mean(axis=None)\n",
    "print(mean/len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(loaded_model.input, loaded_model.layers[3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = x_test[0].reshape(1, x_test[0].shape[0], x_test[0].shape[1])\n",
    "latent_vector = []\n",
    "for x in x_test:\n",
    "    x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "    latent_vector.append(encoder.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_save/mse_cce_models/weights' + '{epoch:02d}-{loss:.4f}.h5'\n",
    "early_stopping_callback = EarlyStopping(monitor='loss', patience=200)\n",
    "checkpoint_callback = ModelCheckpoint(model_path, monitor='loss', verbose = 1, save_best_only = True, save_weights_only = True, mode='min')#, period=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
