{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob, os\n",
    "from keras import layers as ly\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Lambda\n",
    "from keras import losses\n",
    "from keras.models import model_from_json\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir = './sequence/*'\n",
    "dir = './datasets/latest_seq/bfs-character/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file read\n",
    "all_names = []\n",
    "all_data = []\n",
    "sequence_length = []\n",
    "alpha = list(string.ascii_uppercase)\n",
    "data_length = len(glob.glob(dir))\n",
    "file_predix = './datasets/latest_seq/bfs-character/graph'\n",
    "for index in range(data_length):\n",
    "    filename = file_predix + str(index) + \"-*\"\n",
    "    files = glob.glob(filename)\n",
    "    for file in files:\n",
    "        datasets = []\n",
    "        all_names.append(file.split('/')[-1].replace('.txt', ''))\n",
    "        for rf in open(file, 'r'):\n",
    "            (u, v, w) = rf[1:-2].split(', ')\n",
    "            datasets.append([alpha.index(u[1])+1, alpha.index(v[1]) +1, float(w)])\n",
    "        sequence_length.append(len(datasets))\n",
    "        all_data.append(datasets)\n",
    "all_data = np.array([np.array(arr) for arr in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, train_name, test_name = train_test_split(all_data, all_names, test_size=0.3)\n",
    "x_test, x_val, test_name, val_name = train_test_split(x_test, test_name, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name\n",
    "tr_names= []\n",
    "for name in train_name:\n",
    "    tr_names.append(name.split('-')[0].replace('graph', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max(sequence_length)\n",
    "n_features = 3\n",
    "batch_size = 32\n",
    "epochs = 500\n",
    "steps_per_epoch = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    loss1 = losses.mean_squared_error(y_true, y_pred)\n",
    "    loss2 = losses.categorical_crossentropy(y_true, y_pred)\n",
    "    return loss1 * 0.7 + loss2 * 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def repeat_vector(args):\n",
    "    layer_to_repeat = args[0]\n",
    "    sequence_layer = args[1]\n",
    "    return RepeatVector(K.shape(sequence_layer)[1])(layer_to_repeat)\n",
    "    \n",
    "\n",
    "inputs = Input(shape=(None, 3))\n",
    "encoded = LSTM(128, return_sequences=True)(inputs)  #activation 안적으면 tanh\n",
    "encoded = LSTM(64)(encoded)\n",
    "\n",
    "decoded = Lambda(repeat_vector, output_shape=(None, 64)) ([encoded, inputs]) # inputs의 shape[1] 만큼 encoded 를 반복 생성\n",
    "\n",
    "decoded = LSTM(64, return_sequences=True)(decoded)\n",
    "decoded = LSTM(128, return_sequences=True)(decoded)\n",
    "decoded = TimeDistributed(Dense(3))(decoded)\n",
    "encoder = Model(inputs, encoded)\n",
    "\n",
    "lstm_autoencoder = Model(inputs, decoded)\n",
    "lstm_autoencoder.compile(loss=custom_loss, optimizer='adam')#lr=1e-2, decay=0.9))\n",
    "#lstm_autoencoder_500 = lstm_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_generator(x_val):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        yield np.array([x_val[idx]]), np.array([x_val[idx]])\n",
    "        idx += 1\n",
    "        if idx >= len(x_val):\n",
    "            idx = 0\n",
    "\n",
    "def train_generator(x_train):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        yield np.array([x_train[idx]]), np.array([x_train[idx]])\n",
    "        idx += 1\n",
    "        if idx >= len(x_train):\n",
    "            idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/cs405a/anaconda3/envs/graph/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/300\n",
      "4914/4914 [==============================] - 45s 9ms/step - loss: 31.0312 - val_loss: 20.8686\n",
      "Epoch 2/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 17.9892 - val_loss: 17.4468\n",
      "Epoch 3/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 15.8705 - val_loss: 15.3976\n",
      "Epoch 4/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 14.3752 - val_loss: 13.9910\n",
      "Epoch 5/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 12.9853 - val_loss: 13.3626\n",
      "Epoch 6/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 11.9114 - val_loss: 12.7786\n",
      "Epoch 7/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 10.9191 - val_loss: 10.9334\n",
      "Epoch 8/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 10.2605 - val_loss: 10.3265\n",
      "Epoch 9/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 9.6532 - val_loss: 10.0169\n",
      "Epoch 10/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 9.1876 - val_loss: 9.3541\n",
      "Epoch 11/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 8.8874 - val_loss: 9.4315\n",
      "Epoch 12/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 8.5717 - val_loss: 8.9820\n",
      "Epoch 13/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 8.3667 - val_loss: 8.5478\n",
      "Epoch 14/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 8.1041 - val_loss: 8.5827\n",
      "Epoch 15/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 7.8887 - val_loss: 8.0995\n",
      "Epoch 16/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 7.7045 - val_loss: 7.8864\n",
      "Epoch 17/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 7.6080 - val_loss: 7.8045\n",
      "Epoch 18/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 7.4305 - val_loss: 7.7160\n",
      "Epoch 19/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 7.3522 - val_loss: 7.9036\n",
      "Epoch 20/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 7.2507 - val_loss: 7.4936\n",
      "Epoch 21/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 7.1837 - val_loss: 7.4929\n",
      "Epoch 22/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 7.0888 - val_loss: 7.3931\n",
      "Epoch 23/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 7.0575 - val_loss: 7.3324\n",
      "Epoch 24/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.9732 - val_loss: 7.2372\n",
      "Epoch 25/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.9314 - val_loss: 7.3081\n",
      "Epoch 26/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.8995 - val_loss: 7.1602\n",
      "Epoch 27/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.8684 - val_loss: 7.2564\n",
      "Epoch 28/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.8341 - val_loss: 7.2716\n",
      "Epoch 29/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.7775 - val_loss: 7.5678\n",
      "Epoch 30/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.7775 - val_loss: 7.1946\n",
      "Epoch 31/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.7451 - val_loss: 7.0747\n",
      "Epoch 32/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.7263 - val_loss: 7.1036\n",
      "Epoch 33/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.6797 - val_loss: 6.9927\n",
      "Epoch 34/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.6746 - val_loss: 6.9699\n",
      "Epoch 35/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.6648 - val_loss: 7.0778\n",
      "Epoch 36/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.6434 - val_loss: 7.4355\n",
      "Epoch 37/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.6470 - val_loss: 7.1010\n",
      "Epoch 38/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.6386 - val_loss: 7.0849\n",
      "Epoch 39/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.6039 - val_loss: 7.2009\n",
      "Epoch 40/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.6033 - val_loss: 7.3942\n",
      "Epoch 41/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.5915 - val_loss: 6.9024\n",
      "Epoch 42/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.5663 - val_loss: 6.8994\n",
      "Epoch 43/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.5539 - val_loss: 6.8596\n",
      "Epoch 44/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.5660 - val_loss: 6.8663\n",
      "Epoch 45/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.5893 - val_loss: 6.8287\n",
      "Epoch 46/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.5402 - val_loss: 7.0549\n",
      "Epoch 47/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.5275 - val_loss: 6.9120\n",
      "Epoch 48/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.5279 - val_loss: 7.2161\n",
      "Epoch 49/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.5200 - val_loss: 7.1234\n",
      "Epoch 50/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.5076 - val_loss: 6.8450\n",
      "Epoch 51/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.4907 - val_loss: 6.7873\n",
      "Epoch 52/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.4920 - val_loss: 6.8290\n",
      "Epoch 53/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.4995 - val_loss: 6.9317\n",
      "Epoch 54/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.4758 - val_loss: 6.8787\n",
      "Epoch 55/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.4923 - val_loss: 6.8602\n",
      "Epoch 56/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.4501 - val_loss: 6.7269\n",
      "Epoch 57/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.4684 - val_loss: 6.7360\n",
      "Epoch 58/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4552 - val_loss: 6.8368\n",
      "Epoch 59/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4999 - val_loss: 6.8567\n",
      "Epoch 60/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4441 - val_loss: 7.0870\n",
      "Epoch 61/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4466 - val_loss: 7.1218\n",
      "Epoch 62/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4438 - val_loss: 6.9591\n",
      "Epoch 63/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4391 - val_loss: 6.7643\n",
      "Epoch 64/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4359 - val_loss: 6.9269\n",
      "Epoch 65/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4347 - val_loss: 6.8590\n",
      "Epoch 66/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4307 - val_loss: 6.7039\n",
      "Epoch 67/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4215 - val_loss: 6.7315\n",
      "Epoch 68/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4732 - val_loss: 6.6900\n",
      "Epoch 69/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4523 - val_loss: 6.6977\n",
      "Epoch 70/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4514 - val_loss: 6.7936\n",
      "Epoch 71/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4382 - val_loss: 6.7545\n",
      "Epoch 72/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4040 - val_loss: 6.8130\n",
      "Epoch 73/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.4118 - val_loss: 6.6684\n",
      "Epoch 74/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.4075 - val_loss: 6.7167\n",
      "Epoch 75/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.4055 - val_loss: 6.8479\n",
      "Epoch 76/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.4053 - val_loss: 6.8147\n",
      "Epoch 77/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3927 - val_loss: 6.6955\n",
      "Epoch 78/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3943 - val_loss: 6.7488\n",
      "Epoch 79/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.4065 - val_loss: 6.6837\n",
      "Epoch 80/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3806 - val_loss: 6.6381\n",
      "Epoch 81/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3908 - val_loss: 6.8037\n",
      "Epoch 82/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.4518 - val_loss: 6.6165\n",
      "Epoch 83/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.4023 - val_loss: 6.6584\n",
      "Epoch 84/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3904 - val_loss: 6.6212\n",
      "Epoch 85/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3893 - val_loss: 6.6884\n",
      "Epoch 86/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3694 - val_loss: 6.7630\n",
      "Epoch 87/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3909 - val_loss: 6.7461\n",
      "Epoch 88/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3699 - val_loss: 6.7365\n",
      "Epoch 89/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.4317 - val_loss: 6.6566\n",
      "Epoch 90/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3539 - val_loss: 6.6187\n",
      "Epoch 91/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3911 - val_loss: 6.6531\n",
      "Epoch 92/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3889 - val_loss: 6.9715\n",
      "Epoch 93/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3800 - val_loss: 6.6373\n",
      "Epoch 94/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3715 - val_loss: 6.6501\n",
      "Epoch 95/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.4662 - val_loss: 6.6263\n",
      "Epoch 96/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3567 - val_loss: 6.6657\n",
      "Epoch 97/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3652 - val_loss: 6.7383\n",
      "Epoch 98/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3628 - val_loss: 6.6331\n",
      "Epoch 99/300\n",
      "4914/4914 [==============================] - 43s 9ms/step - loss: 6.3602 - val_loss: 6.7202\n",
      "Epoch 100/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4228 - val_loss: 6.6813\n",
      "Epoch 101/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3342 - val_loss: 6.6445\n",
      "Epoch 102/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3512 - val_loss: 6.6893\n",
      "Epoch 103/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4206 - val_loss: 6.6891\n",
      "Epoch 104/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3400 - val_loss: 6.5934\n",
      "Epoch 105/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3553 - val_loss: 6.6413\n",
      "Epoch 106/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4275 - val_loss: 6.6407\n",
      "Epoch 107/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3322 - val_loss: 6.6550\n",
      "Epoch 108/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3453 - val_loss: 6.7074\n",
      "Epoch 109/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3519 - val_loss: 6.6338\n",
      "Epoch 110/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3404 - val_loss: 6.5991\n",
      "Epoch 111/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3525 - val_loss: 6.7171\n",
      "Epoch 112/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3339 - val_loss: 6.6355\n",
      "Epoch 113/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3282 - val_loss: 6.6494\n",
      "Epoch 114/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3379 - val_loss: 6.5796\n",
      "Epoch 115/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3862 - val_loss: 6.6512\n",
      "Epoch 116/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3274 - val_loss: 6.6936\n",
      "Epoch 117/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3604 - val_loss: 6.6730\n",
      "Epoch 118/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3229 - val_loss: 6.6506\n",
      "Epoch 119/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3264 - val_loss: 6.5787\n",
      "Epoch 120/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3998 - val_loss: 6.6336\n",
      "Epoch 121/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4015 - val_loss: 6.6558\n",
      "Epoch 122/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3549 - val_loss: 6.6643\n",
      "Epoch 123/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3206 - val_loss: 6.7481\n",
      "Epoch 124/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.4384 - val_loss: 6.6042\n",
      "Epoch 125/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3159 - val_loss: 6.6471\n",
      "Epoch 126/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3306 - val_loss: 7.3853\n",
      "Epoch 127/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3261 - val_loss: 6.5879\n",
      "Epoch 128/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3634 - val_loss: 6.6103\n",
      "Epoch 129/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3306 - val_loss: 6.5732\n",
      "Epoch 130/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3515 - val_loss: 6.6339\n",
      "Epoch 131/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3161 - val_loss: 6.6258\n",
      "Epoch 132/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3200 - val_loss: 6.6158\n",
      "Epoch 133/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3628 - val_loss: 6.7187\n",
      "Epoch 134/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3173 - val_loss: 6.6536\n",
      "Epoch 135/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3796 - val_loss: 6.7838\n",
      "Epoch 136/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3662 - val_loss: 6.5797\n",
      "Epoch 137/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3305 - val_loss: 6.7094\n",
      "Epoch 138/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3148 - val_loss: 6.6576\n",
      "Epoch 139/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3189 - val_loss: 6.5850\n",
      "Epoch 140/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3313 - val_loss: 6.5953\n",
      "Epoch 141/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3166 - val_loss: 6.6451\n",
      "Epoch 142/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3157 - val_loss: 6.6295\n",
      "Epoch 143/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3135 - val_loss: 6.6596\n",
      "Epoch 144/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3121 - val_loss: 6.6472\n",
      "Epoch 145/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3102 - val_loss: 6.5784\n",
      "Epoch 146/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3144 - val_loss: 6.6241\n",
      "Epoch 147/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3072 - val_loss: 6.7242\n",
      "Epoch 148/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3268 - val_loss: 6.6805\n",
      "Epoch 149/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3171 - val_loss: 6.5948\n",
      "Epoch 150/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3312 - val_loss: 6.6428\n",
      "Epoch 151/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3539 - val_loss: 6.8481\n",
      "Epoch 152/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3562 - val_loss: 6.5978\n",
      "Epoch 153/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3738 - val_loss: 6.5891\n",
      "Epoch 154/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3036 - val_loss: 6.6279\n",
      "Epoch 155/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3120 - val_loss: 6.6004\n",
      "Epoch 156/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3548 - val_loss: 6.6382\n",
      "Epoch 157/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.4523 - val_loss: 6.6471\n",
      "Epoch 158/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3307 - val_loss: 6.5642\n",
      "Epoch 159/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3340 - val_loss: 6.5467\n",
      "Epoch 160/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3124 - val_loss: 6.6290\n",
      "Epoch 161/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3136 - val_loss: 6.5901\n",
      "Epoch 162/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3076 - val_loss: 6.6023\n",
      "Epoch 163/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3060 - val_loss: 6.5750\n",
      "Epoch 164/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3003 - val_loss: 6.5723\n",
      "Epoch 165/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3157 - val_loss: 6.6793\n",
      "Epoch 166/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3275 - val_loss: 6.5438\n",
      "Epoch 167/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2938 - val_loss: 6.6258\n",
      "Epoch 168/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3126 - val_loss: 7.2810\n",
      "Epoch 169/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3598 - val_loss: 6.6783\n",
      "Epoch 170/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2981 - val_loss: 6.6745\n",
      "Epoch 171/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3161 - val_loss: 6.6523\n",
      "Epoch 172/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3123 - val_loss: 6.5930\n",
      "Epoch 173/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3002 - val_loss: 6.5691\n",
      "Epoch 174/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3645 - val_loss: 6.7907\n",
      "Epoch 175/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3374 - val_loss: 6.5734\n",
      "Epoch 176/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2961 - val_loss: 6.6183\n",
      "Epoch 177/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2954 - val_loss: 6.5606\n",
      "Epoch 178/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2963 - val_loss: 6.5672\n",
      "Epoch 179/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2957 - val_loss: 6.6015\n",
      "Epoch 180/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2918 - val_loss: 6.5547\n",
      "Epoch 181/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2941 - val_loss: 6.6280\n",
      "Epoch 182/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3847 - val_loss: 6.5517\n",
      "Epoch 183/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2824 - val_loss: 6.5748\n",
      "Epoch 184/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3014 - val_loss: 6.5664\n",
      "Epoch 185/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2866 - val_loss: 6.5574\n",
      "Epoch 186/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2899 - val_loss: 6.6354\n",
      "Epoch 187/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3090 - val_loss: 6.5528\n",
      "Epoch 188/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2825 - val_loss: 6.5462\n",
      "Epoch 189/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2881 - val_loss: 6.5645\n",
      "Epoch 190/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3569 - val_loss: 6.6042\n",
      "Epoch 191/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2887 - val_loss: 6.6181\n",
      "Epoch 192/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2859 - val_loss: 6.6229\n",
      "Epoch 193/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2987 - val_loss: 6.5669\n",
      "Epoch 194/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3065 - val_loss: 6.6150\n",
      "Epoch 195/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3026 - val_loss: 6.5955\n",
      "Epoch 196/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2948 - val_loss: 6.5764\n",
      "Epoch 197/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3000 - val_loss: 6.5900\n",
      "Epoch 198/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2875 - val_loss: 6.6400\n",
      "Epoch 199/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2909 - val_loss: 6.5861\n",
      "Epoch 200/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2892 - val_loss: 6.6058\n",
      "Epoch 201/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2826 - val_loss: 6.5846\n",
      "Epoch 202/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.4116 - val_loss: 6.6817\n",
      "Epoch 203/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3383 - val_loss: 6.5662\n",
      "Epoch 204/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2952 - val_loss: 6.5999\n",
      "Epoch 205/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3004 - val_loss: 6.6205\n",
      "Epoch 206/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2971 - val_loss: 6.6055\n",
      "Epoch 207/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2894 - val_loss: 6.5529\n",
      "Epoch 208/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2800 - val_loss: 6.6170\n",
      "Epoch 209/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2831 - val_loss: 6.5680\n",
      "Epoch 210/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3111 - val_loss: 6.5510\n",
      "Epoch 211/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2682 - val_loss: 6.6033\n",
      "Epoch 212/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2902 - val_loss: 6.6128\n",
      "Epoch 213/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2824 - val_loss: 6.5673\n",
      "Epoch 214/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2815 - val_loss: 6.6216\n",
      "Epoch 215/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2765 - val_loss: 6.6176\n",
      "Epoch 216/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2776 - val_loss: 6.6130\n",
      "Epoch 217/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3142 - val_loss: 7.1579\n",
      "Epoch 218/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3705 - val_loss: 6.9113\n",
      "Epoch 219/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3100 - val_loss: 6.5689\n",
      "Epoch 220/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2860 - val_loss: 6.6201\n",
      "Epoch 221/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2825 - val_loss: 6.5936\n",
      "Epoch 222/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2874 - val_loss: 6.6110\n",
      "Epoch 223/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2781 - val_loss: 6.6013\n",
      "Epoch 224/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2816 - val_loss: 6.5985\n",
      "Epoch 225/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3362 - val_loss: 6.5468\n",
      "Epoch 226/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3103 - val_loss: 6.5506\n",
      "Epoch 227/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3131 - val_loss: 6.5898\n",
      "Epoch 228/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3090 - val_loss: 6.5460\n",
      "Epoch 229/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3429 - val_loss: 6.5659\n",
      "Epoch 230/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2838 - val_loss: 6.6092\n",
      "Epoch 231/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3750 - val_loss: 6.5528\n",
      "Epoch 232/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2858 - val_loss: 6.5896\n",
      "Epoch 233/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2974 - val_loss: 6.5526\n",
      "Epoch 234/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3683 - val_loss: 6.5882\n",
      "Epoch 235/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3068 - val_loss: 6.6062\n",
      "Epoch 236/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2819 - val_loss: 6.5602\n",
      "Epoch 237/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2807 - val_loss: 6.5620\n",
      "Epoch 238/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2774 - val_loss: 6.5729\n",
      "Epoch 239/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2969 - val_loss: 6.5614\n",
      "Epoch 240/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2925 - val_loss: 6.5790\n",
      "Epoch 241/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2843 - val_loss: 6.6017\n",
      "Epoch 242/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2793 - val_loss: 6.5577\n",
      "Epoch 243/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2765 - val_loss: 6.5753\n",
      "Epoch 244/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2734 - val_loss: 6.5835\n",
      "Epoch 245/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2710 - val_loss: 6.5720\n",
      "Epoch 246/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2652 - val_loss: 6.5940\n",
      "Epoch 247/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2701 - val_loss: 6.5541\n",
      "Epoch 248/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2804 - val_loss: 6.5551\n",
      "Epoch 249/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3248 - val_loss: 6.6313\n",
      "Epoch 250/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3439 - val_loss: 6.5851\n",
      "Epoch 251/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2558 - val_loss: 6.5970\n",
      "Epoch 252/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2725 - val_loss: 6.5916\n",
      "Epoch 253/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2686 - val_loss: 6.6019\n",
      "Epoch 254/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2880 - val_loss: 6.6220\n",
      "Epoch 255/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2655 - val_loss: 6.6355\n",
      "Epoch 256/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2767 - val_loss: 6.6474\n",
      "Epoch 257/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2638 - val_loss: 6.5467\n",
      "Epoch 258/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2677 - val_loss: 6.5714\n",
      "Epoch 259/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2679 - val_loss: 6.6787\n",
      "Epoch 260/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2646 - val_loss: 6.5881\n",
      "Epoch 261/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2756 - val_loss: 6.5660\n",
      "Epoch 262/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2830 - val_loss: 6.6357\n",
      "Epoch 263/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2591 - val_loss: 6.6083\n",
      "Epoch 264/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2938 - val_loss: 6.6129\n",
      "Epoch 265/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2654 - val_loss: 6.6233\n",
      "Epoch 266/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2886 - val_loss: 6.6828\n",
      "Epoch 267/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2749 - val_loss: 6.6846\n",
      "Epoch 268/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2610 - val_loss: 6.6810\n",
      "Epoch 269/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2633 - val_loss: 6.6105\n",
      "Epoch 270/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.2592 - val_loss: 6.6609\n",
      "Epoch 271/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2993 - val_loss: 6.5724\n",
      "Epoch 272/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2693 - val_loss: 6.5845\n",
      "Epoch 273/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2624 - val_loss: 6.5811\n",
      "Epoch 274/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2618 - val_loss: 6.5582\n",
      "Epoch 275/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2878 - val_loss: 6.7277\n",
      "Epoch 276/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.2764 - val_loss: 6.5616\n",
      "Epoch 277/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2780 - val_loss: 6.6154\n",
      "Epoch 278/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.2542 - val_loss: 6.5733\n",
      "Epoch 279/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2641 - val_loss: 6.5626\n",
      "Epoch 280/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2572 - val_loss: 6.6672\n",
      "Epoch 281/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2820 - val_loss: 6.5375\n",
      "Epoch 282/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.2582 - val_loss: 6.5790\n",
      "Epoch 283/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2563 - val_loss: 6.5902\n",
      "Epoch 284/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.5321 - val_loss: 6.7829\n",
      "Epoch 285/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.3945 - val_loss: 6.6680\n",
      "Epoch 286/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.4962 - val_loss: 6.6720\n",
      "Epoch 287/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3225 - val_loss: 6.5934\n",
      "Epoch 288/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2801 - val_loss: 6.6461\n",
      "Epoch 289/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2767 - val_loss: 6.5777\n",
      "Epoch 290/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.2669 - val_loss: 6.5889\n",
      "Epoch 291/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.3791 - val_loss: 6.5940\n",
      "Epoch 292/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2770 - val_loss: 6.6223\n",
      "Epoch 293/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.2747 - val_loss: 6.6165\n",
      "Epoch 294/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.2642 - val_loss: 6.6584\n",
      "Epoch 295/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2620 - val_loss: 6.5436\n",
      "Epoch 296/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.2597 - val_loss: 6.5496\n",
      "Epoch 297/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.2686 - val_loss: 6.6518\n",
      "Epoch 298/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2537 - val_loss: 6.6066\n",
      "Epoch 299/300\n",
      "4914/4914 [==============================] - 41s 8ms/step - loss: 6.2558 - val_loss: 6.6250\n",
      "Epoch 300/300\n",
      "4914/4914 [==============================] - 40s 8ms/step - loss: 6.2561 - val_loss: 6.5398\n"
     ]
    }
   ],
   "source": [
    "hist = lstm_autoencoder.fit_generator(train_generator(x_train), epochs=300, steps_per_epoch=steps_per_epoch, verbose=1, validation_steps=len(x_val), validation_data=val_generator(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = lstm_autoencoder.to_json()\n",
    "filename = 'new_mse_lstmae_cce'  #input('filename: ') #\n",
    "with open('model_save/mse_cce_models/' + filename + '.json', 'w') as file:\n",
    "    file.write(model_json)\n",
    "lstm_autoencoder.save_weights('model_save/mse_cce_models/weights_' +  filename + '.h5')\n",
    "\n",
    "with open('model_save/mse_cce_models/new_cce_histroy.json', 'w') as f:\n",
    "    json.dump(hist.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "loss_ax.plot(hist.history['val_loss'], 'b', label='val loss')\n",
    "loss_ax.plot(hist.history['loss'], 'r', label='train loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "plt.title('mse_cce')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"last_mse_lstmae_cce\"\n",
    "loaded_model = model_from_json(open('model_save/mse_cce_models/' +filename + '.json').read())\n",
    "loaded_model.load_weights('model_save/mse_cce_models/weights_' + filename + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = lstm_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42748804352238495\n"
     ]
    }
   ],
   "source": [
    "mean= 0\n",
    "for xt in x_test:\n",
    "    xt = xt.reshape(1, xt.shape[0], xt.shape[1])\n",
    "    out = loaded_model.predict(xt)\n",
    "    mean += ((xt-out)**2).mean(axis=None)\n",
    "print(mean/len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(loaded_model.input, loaded_model.layers[3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = x_test[0].reshape(1, x_test[0].shape[0], x_test[0].shape[1])\n",
    "latent_vector = []\n",
    "for x in x_test:\n",
    "    x = x.reshape(1, x.shape[0], x.shape[1])\n",
    "    latent_vector.append(encoder.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_save/mse_cce_models/weights' + '{epoch:02d}-{loss:.4f}.h5'\n",
    "early_stopping_callback = EarlyStopping(monitor='loss', patience=200)\n",
    "checkpoint_callback = ModelCheckpoint(model_path, monitor='loss', verbose = 1, save_best_only = True, save_weights_only = True, mode='min')#, period=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
